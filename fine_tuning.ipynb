{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbeea47a-082e-4810-96c2-7bc3e244bb1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-Tuning the GPTJ-6B model using transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691d819-deef-46e2-aeac-547f2a2c253a",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will walk you through how to fine-tune a pre-trained large language model with domain specific knowledge. \n",
    "\n",
    "The domain specific dataset that we will be using to fine-tune the the model will be United Kingdom (U.K.) Supreme Court case documents. We will tune the model on roughly 693 legal documents. \n",
    "\n",
    "## Dataset info\n",
    "* <strong>Page count:</strong> ~17,718\n",
    "* <strong>Word count:</strong> 10,015,333\n",
    "* <strong>Characters (no spaces):</strong> 49,897,639\n",
    "\n",
    "The entire dataset is publically available and can be download [here](https://zenodo.org/record/7152317#.ZCSfaoTMI2y)\n",
    "\n",
    "## Considerations when fine-tuning the model\n",
    "The notebook has been configured to allow you to only use a subset of the entire dataset to fine-tune the model if you would like. There is a variable named _**doc_count**_ in the _**Data Prep**_ section. You can set this number to whatever you would like and it will only fine-tune the model based on the number of documents you set this variable to. The smaller this value the faster the model will fine-tune.\n",
    "    \n",
    "## Training/Tuning Time estimates\n",
    "\n",
    "Here are the estimated training times based on total number of case documents in the training dataset.\n",
    "\n",
    "#### All training was ran on 1 - *ml.p3dn.24xlarge* instance\n",
    "\n",
    "#### <strong>Training dataset document count </strong> 250\n",
    "Training time: 1 hour 41 minutes\n",
    "\n",
    "#### <strong>Training document count</strong> 500\n",
    "Training time: 2 hours 57 minutes\n",
    "\n",
    "#### <strong>Training document count</strong> 693\n",
    "Training time: 5 hour 30 minutes\n",
    "\n",
    "\n",
    "## GPTJ-6B base model\n",
    "\n",
    "Steps you will go through to test the base model\n",
    "\n",
    "1. Install needed notebook libraries\n",
    "3. Configure the notebook to use SageMaker\n",
    "4. Retrieve base model container\n",
    "5. Deploy inference endpoint\n",
    "6. Call inference endpoint to retrieve results from the LLM\n",
    "\n",
    "## Fine-tuned model\n",
    "\n",
    "Steps you will go through to test the fine-tuned model\n",
    "\n",
    "1. Download dataset\n",
    "2. Prep the dataset\n",
    "3. Retrieve model container\n",
    "4. Set hyperparameters for fine-tuning\n",
    "5. Start training/tuning job\n",
    "6. Deploy inference endpoint for the fine-tuned model\n",
    "7. Call inference endpoint for the fine-tuned model\n",
    "8. Parse endpoint results\n",
    "\n",
    "### Final Step\n",
    "* Be sure you delete all models and endpoints to avoid incurring spend\n",
    "    \n",
    "### Disclaimer\n",
    "This notebook demos how you can fine-tune an LLM using transfer learning. Even though this notebook is fine-tuned using actual (U.K.) Supreme Court case documents you should not use this notebook for legal advise.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba73fc7-29bc-4ef0-ae1b-84608c8916e4",
   "metadata": {},
   "source": [
    "## Install Pre Reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a147b-4f15-4aca-b114-5f7712b98a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade sagemaker --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d018169-b534-4a5c-9d3a-31478899048f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker SDK configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ffff26-5802-4397-8302-aefe25762051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::938247108506:role/service-role/AmazonSageMaker-ExecutionRole-20230622T124468\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print(aws_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0b553-65bd-4d12-946a-e4fa30092e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploying interence endpoint for the GPTJ-6 base model\n",
    "\n",
    "In this section we are deploying the HuggingFace GPTJ-6B base model in order to compare the inference results with the fine-tuned model we will tune later.\n",
    "\n",
    "The fine-tuned model will be trained on UK Supreme Court case documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2935e7a5-9772-467b-93a6-31a8cc62128a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id, model_version = \"huggingface-textgeneration1-gpt-j-6b\", \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbd31d-c031-433e-94af-0b976e53cbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{model_id}\")\n",
    "\n",
    "inference_instance_type = \"ml.g5.12xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "print(deploy_image_uri)\n",
    "\n",
    "# Retrieve the model uri.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "print(model_uri)\n",
    "\n",
    "# Create the SageMaker model instance. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")\n",
    "\n",
    "# deploy the Model. TODO\n",
    "base_model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n",
    "\n",
    "print(base_model_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3861a00-903d-4fa9-b746-52646f60a33b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference Helper functions\n",
    "Creates two helper functions that will be used when we call the inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b2203-ab30-4ed7-ac71-750d02ff4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    generated_text = []\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    return model_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b9753-3541-4b17-b847-15bb93165f6d",
   "metadata": {},
   "source": [
    "## Call GPTJ-6B inference endpoint\n",
    "In this section we make a call to the SageMaker inference point that host the base model and have the results returned back from the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477372a9-0015-44d1-9102-9cae8350e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_length\": 500,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.8,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 1,\n",
    "}\n",
    "\n",
    "res_gpt_before_finetune = []\n",
    "\n",
    "for quota_text in [\n",
    "    \"Tell me about the Matrimonial and Family Proceedings Act 1984\",\n",
    "]:\n",
    "    payload = {\"text_inputs\": f\"{quota_text}:\", **parameters}\n",
    "\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response_multiple_texts(query_response)[0][\"generated_text\"]\n",
    "    res_gpt_before_finetune.append(generated_texts)\n",
    "    print(generated_texts)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c71a7-ff21-4420-b825-5ad41dedeec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Base model results\n",
    "The output above is what the base model will return to use before fine-tuning the model. It will only return with data that it knows about when the model was pre-trained. The goal is to make the model give us better results after it has more context based on case law that it will be fine-tuned with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4e794-8fdf-4d6c-88d2-24f78ef2451b",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "Delete the SageMaker endpoint and the attached resources once you no longer endpoint them. The inteference endpoints incur cost if you leave them running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bda62-9280-4d43-8bfc-2c2b558ee750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_predictor.delete_model()\n",
    "base_model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e329fd-f742-4689-a7e6-64ec074f96f6",
   "metadata": {},
   "source": [
    "# Fine-Tuning the GPTJ-6 base model via transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7bc3d-3493-45a4-ac3f-0edc291a3a6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Prep\n",
    "\n",
    "Download the dataset. This may take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ecba-521a-41da-b8e3-75b71f193dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/record/7152317/files/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397e3ca-d7fd-41e5-9c3d-d6db78f5f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzipping compressed datasets\n",
    "\n",
    "print(\"unzipping file\")\n",
    "\n",
    "!unzip -q dataset.zip\n",
    "\n",
    "print(\"finished unzipping file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6323e4-2cb1-4525-876c-19810a173481",
   "metadata": {},
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abed6e70-bfe0-42aa-abaa-f4cb59ab9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n",
      "Training dataset created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace 'path/to/your/directory' with the actual path to your directory containing the text files\n",
    "directory_path = 'dataset/UK-Abs/train-data/judgement'\n",
    "train_file = 'dataset/train.txt'\n",
    "\n",
    "# Replace 'new_file.txt' with the name of the new file where you want to combine the contents\n",
    "new_file_path = 'dataset/train.txt'\n",
    "\n",
    "bucket_name = 'shelside-sagemaker' # change this to your bucket name and be sure it exist in S3\n",
    "training_folder = r'train' # the training folder in your bucket\n",
    "\n",
    "# number of documents to include the fine-tuning dataset\n",
    "doc_count = 694\n",
    "doc_in_dataset = 0\n",
    "\n",
    "# Loop through each file and append its content to the new file\n",
    "with open(new_file_path, 'w') as new_file:\n",
    "    file_list = os.listdir(directory_path)\n",
    "    for filename in file_list:\n",
    "        if doc_in_dataset < doc_count:\n",
    "            doc_in_dataset+=1\n",
    "            # Create the full file path by joining the directory path with the filename\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Check if the file is a regular file (not a directory)\n",
    "            if os.path.isfile(file_path):\n",
    "                # Open the file in read mode\n",
    "                with open(file_path, 'r') as file:\n",
    "                    text_content = file.read()\n",
    "\n",
    "                # Write the content of each file to the new file\n",
    "                new_file.write(text_content)\n",
    "                new_file.write(\"\\n-----------------------------------------------------------------\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "print(doc_in_dataset)\n",
    "            \n",
    "print(\"Training dataset created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3267fe0-19a4-4b30-84a7-67818e3e3e8a",
   "metadata": {},
   "source": [
    "## Upload training data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44ba081-dc0a-46ac-96ad-9b9746913708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to S3\n"
     ]
    }
   ],
   "source": [
    "# uploads training data to S3 so that model can be fine-tune using the dataset\n",
    "sagemaker_session.upload_data(train_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_folder)\n",
    "\n",
    "print(\"Training data uploaded to S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66edbd-4d81-47e6-aa10-69dc18d7dd0b",
   "metadata": {},
   "source": [
    "## Setup Model to be tuned\n",
    "\n",
    "When selecting your instance type below ensure you have the minimal available to run based on your account quota. For some GPU based instances you may need to request an increase in the total number you can run in your account. This is true for spot instance type also which have a separate quota. \n",
    "\n",
    "You can request a service increase [here](https://us-east-1.console.aws.amazon.com/servicequotas/home/services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f44205-2436-4f4c-883d-9bb2eeacc67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz\n",
      "s3://jumpstart-cache-prod-us-east-1/huggingface-training/train-huggingface-textgeneration1-gpt-j-6b.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_id, model_version = \"huggingface-textgeneration1-gpt-j-6b\", \"*\"\n",
    "\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "# ml.g5.24xlarge\n",
    "# training_instance_type = \"ml.g5.12xlarge\"\n",
    "\n",
    "# training_instance_type = \"ml.g4dn.12xlarge\"\n",
    "\n",
    "training_instance_type = \"ml.p3dn.24xlarge\" \n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "\n",
    "print(train_source_uri)\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")\n",
    "\n",
    "print(train_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73892e-1f0f-460f-9341-ab9670013d69",
   "metadata": {},
   "source": [
    "## Configure storage locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b509def4-9ad9-46f6-a296-1584783b0b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumpstart-cache-prod-us-east-1\n",
      "s3://shelside-sagemaker/train/\n",
      "s3://shelside-sagemaker/validation/\n",
      "s3://shelside-sagemaker/training/output\n"
     ]
    }
   ],
   "source": [
    "# Sample training data is available in this bucket\n",
    "data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "data_prefix = \"training-datasets\"\n",
    "print(data_bucket)\n",
    "\n",
    "bucket_name = \"shelside-sagemaker\"\n",
    "training_dataset_s3_path = f\"s3://{bucket_name}/train/\" \n",
    "validation_dataset_s3_path = f\"s3://{bucket_name}/validation/\"\n",
    "\n",
    "print(training_dataset_s3_path)\n",
    "print(validation_dataset_s3_path)\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"training\"\n",
    "\n",
    "s3_output_location = f\"s3://{bucket_name}/{output_prefix}/output\"\n",
    "\n",
    "print(s3_output_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958b68c-0e43-4488-8f0d-0f1c3c8957ef",
   "metadata": {},
   "source": [
    "## Spot Training configuration\n",
    "If **use_spot_instances** is set to **True** below training will use spot instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51034e0d-7b4d-4802-b330-3cf89e49296c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint uri: None\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "training_job_name = name_from_base(f\"ssides-hugging-face-{model_id}-transfer-learning\")\n",
    "\n",
    "# We will use spot for training\n",
    "use_spot_instances = False\n",
    "max_run = 36000 # in seconds\n",
    "max_wait = 7200 if use_spot_instances else None # in seconds\n",
    "\n",
    "checkpoint_s3_uri = None\n",
    "\n",
    "if use_spot_instances:\n",
    "    checkpoint_s3_uri = f's3://{bucket_name}/{output_prefix}/checkpoints/{training_job_name}'\n",
    "    \n",
    "print (f'Checkpoint uri: {checkpoint_s3_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f090726-2433-455b-abf2-7ef00b2e7b69",
   "metadata": {},
   "source": [
    "## Train with Automatic Model Tuning (HPO)\n",
    "This section configures Automatic Model Tuning if you change from **use_amt = False** to **use_amt = True**. By default we set it to false for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd4a283-f2e5-4bba-ab8e-321ae1111e60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': '3', 'learning_rate': '6e-06', 'per_device_train_batch_size': '4', 'per_device_eval_batch_size': '8', 'warmup_ratio': '0.1', 'instruction_tuned': False, 'train_from_scratch': 'False', 'fp16': 'True', 'bf16': 'False', 'evaluation_strategy': 'steps', 'eval_steps': '20', 'gradient_accumulation_steps': '2', 'logging_steps': '10', 'weight_decay': '0.2', 'load_best_model_at_end': 'True', 'max_train_samples': '-1', 'max_val_samples': '-1', 'seed': '10', 'max_input_length': '-1', 'validation_split_ratio': '0.2', 'train_data_split_seed': '0', 'preprocessing_num_workers': 'None', 'max_steps': '-1', 'gradient_checkpointing': 'True', 'early_stopping_patience': '3', 'early_stopping_threshold': '0.0', 'adam_beta1': '0.9', 'adam_beta2': '0.999', 'adam_epsilon': '1e-08', 'max_grad_norm': '1.0', 'label_smoothing_factor': '0', 'logging_first_step': 'False', 'logging_nan_inf_filter': 'True', 'save_strategy': 'steps', 'save_steps': '500', 'save_total_limit': '1', 'dataloader_drop_last': 'False', 'dataloader_num_workers': '0', 'eval_accumulation_steps': 'None', 'auto_find_batch_size': 'False', 'lr_scheduler_type': 'constant_with_warmup', 'warmup_steps': '0'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"epoch\"] = \"3\"\n",
    "hyperparameters[\"per_device_train_batch_size\"] = \"4\"\n",
    "hyperparameters[\"instruction_tuned\"] = False\n",
    "\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e75710-2c0a-4ed1-8c84-2d05040aa62c",
   "metadata": {},
   "source": [
    "## Set hyperparameters\n",
    "This section configures any hyperparameter you would like to configure before starting the training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b12a8e-bc4b-4938-b4fc-d68dd51b3206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "# Use AMT for tuning and selecting the best model\n",
    "use_amt = False\n",
    "\n",
    "# Define objective metric, based on which the best model will be selected.\n",
    "amt_metric_definitions = {\n",
    "    \"metrics\": [{\"Name\": \"eval:loss\", \"Regex\": \"'eval_loss': ([0-9]+\\.[0-9]+)\"}],\n",
    "    \"type\": \"Minimize\",\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.00001, 0.0001, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dedfd9-841e-4e8f-88a5-6cd17b548230",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "Here we start our SageMaker training job to tune the model. Depending on how much data is being used, the size of your training instance and the number of instances used for training will dictate how long it will take to train/tune your new model.\n",
    "\n",
    "If your training job fails because you surpassed your qouta for that instance type you can request an increase in your quota for that instance type [here](https://us-east-1.console.aws.amazon.com/servicequotas/home/services/sagemaker/quotas). You can request an instance quota increase for regular training instances and spot instances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5a1fa-0461-4191-8121-b07c829d2dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: ssides-hugging-face-huggingface-textgen-2023-08-04-16-25-01-097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-04 16:25:01 Starting - Starting the training job...\n",
      "2023-08-04 16:25:18 Starting - Preparing the instances for training............\n",
      "2023-08-04 16:27:04 Downloading - Downloading input data..................................................................\n",
      "2023-08-04 16:38:32 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:33,780 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:33,837 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:33,845 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:33,847 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:36,448 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/accelerate/accelerate-0.20.3-py3-none-any.whl (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/deepspeed/deepspeed-0.9.3.tar.gz\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mProcessing ./lib/huggingface_hub/huggingface_hub-0.15.1-py3-none-any.whl (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/py_cpuinfo/py_cpuinfo-9.0.0-py3-none-any.whl (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_tabular_script_utilities/sagemaker_jumpstart_tabular_script_utilities-1.0.0-py2.py3-none-any.whl (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_huggingface_script_utilities/sagemaker_jumpstart_huggingface_script_utilities-1.0.5-py2.py3-none-any.whl (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_script_utilities/sagemaker_jumpstart_script_utilities-1.1.8-py2.py3-none-any.whl (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3->-r requirements.txt (line 1)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3->-r requirements.txt (line 1)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.3->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.3->-r requirements.txt (line 2)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.3->-r requirements.txt (line 2)) (1.10.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.3->-r requirements.txt (line 2)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.15.1->-r requirements.txt (line 3)) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.15.1->-r requirements.txt (line 3)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.15.1->-r requirements.txt (line 3)) (2.28.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.15.1->-r requirements.txt (line 3)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 1)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 1)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 1)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.15.1->-r requirements.txt (line 3)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.15.1->-r requirements.txt (line 3)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.15.1->-r requirements.txt (line 3)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.15.1->-r requirements.txt (line 3)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 1)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mpy-cpuinfo is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: deepspeed\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for deepspeed: filename=deepspeed-0.9.3-py3-none-any.whl size=843299 sha256=c90204cf6a3bf41df48c0d9e96e6497dec92e491ee84371b41087135e3fd4f5f\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/e6/0e/61/48552c30a9cd82d794c8a1a914842ecd283612e0925d29314d\u001b[0m\n",
      "\u001b[34mSuccessfully built deepspeed\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sagemaker-jumpstart-tabular-script-utilities, sagemaker-jumpstart-script-utilities, sagemaker-jumpstart-huggingface-script-utilities, huggingface-hub, deepspeed, accelerate\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: deepspeed\u001b[0m\n",
      "\u001b[34mFound existing installation: deepspeed 0.6.1+1ea3d4b\u001b[0m\n",
      "\u001b[34mUninstalling deepspeed-0.6.1+1ea3d4b:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled deepspeed-0.6.1+1ea3d4b\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.20.3 deepspeed-0.9.3 huggingface-hub-0.15.1 sagemaker-jumpstart-huggingface-script-utilities-1.0.5 sagemaker-jumpstart-script-utilities-1.1.8 sagemaker-jumpstart-tabular-script-utilities-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.2.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,396 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,396 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,476 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,543 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,607 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,617 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3dn.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam_beta1\": \"0.9\",\n",
      "        \"adam_beta2\": \"0.999\",\n",
      "        \"adam_epsilon\": \"1e-08\",\n",
      "        \"auto_find_batch_size\": \"False\",\n",
      "        \"bf16\": \"False\",\n",
      "        \"dataloader_drop_last\": \"False\",\n",
      "        \"dataloader_num_workers\": \"0\",\n",
      "        \"early_stopping_patience\": \"3\",\n",
      "        \"early_stopping_threshold\": \"0.0\",\n",
      "        \"epoch\": \"3\",\n",
      "        \"eval_accumulation_steps\": \"None\",\n",
      "        \"eval_steps\": \"20\",\n",
      "        \"evaluation_strategy\": \"steps\",\n",
      "        \"fp16\": \"True\",\n",
      "        \"gradient_accumulation_steps\": \"2\",\n",
      "        \"gradient_checkpointing\": \"True\",\n",
      "        \"instruction_tuned\": false,\n",
      "        \"label_smoothing_factor\": \"0\",\n",
      "        \"learning_rate\": \"6e-06\",\n",
      "        \"load_best_model_at_end\": \"True\",\n",
      "        \"logging_first_step\": \"False\",\n",
      "        \"logging_nan_inf_filter\": \"True\",\n",
      "        \"logging_steps\": \"10\",\n",
      "        \"lr_scheduler_type\": \"constant_with_warmup\",\n",
      "        \"max_grad_norm\": \"1.0\",\n",
      "        \"max_input_length\": \"-1\",\n",
      "        \"max_steps\": \"-1\",\n",
      "        \"max_train_samples\": \"-1\",\n",
      "        \"max_val_samples\": \"-1\",\n",
      "        \"per_device_eval_batch_size\": \"8\",\n",
      "        \"per_device_train_batch_size\": \"4\",\n",
      "        \"preprocessing_num_workers\": \"None\",\n",
      "        \"save_steps\": \"500\",\n",
      "        \"save_strategy\": \"steps\",\n",
      "        \"save_total_limit\": \"1\",\n",
      "        \"seed\": \"10\",\n",
      "        \"train_data_split_seed\": \"0\",\n",
      "        \"train_from_scratch\": \"False\",\n",
      "        \"validation_split_ratio\": \"0.2\",\n",
      "        \"warmup_ratio\": \"0.1\",\n",
      "        \"warmup_steps\": \"0\",\n",
      "        \"weight_decay\": \"0.2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3dn.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"ssides-hugging-face-huggingface-textgen-2023-08-04-16-25-01-097\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3dn.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3dn.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.999\",\"adam_epsilon\":\"1e-08\",\"auto_find_batch_size\":\"False\",\"bf16\":\"False\",\"dataloader_drop_last\":\"False\",\"dataloader_num_workers\":\"0\",\"early_stopping_patience\":\"3\",\"early_stopping_threshold\":\"0.0\",\"epoch\":\"3\",\"eval_accumulation_steps\":\"None\",\"eval_steps\":\"20\",\"evaluation_strategy\":\"steps\",\"fp16\":\"True\",\"gradient_accumulation_steps\":\"2\",\"gradient_checkpointing\":\"True\",\"instruction_tuned\":false,\"label_smoothing_factor\":\"0\",\"learning_rate\":\"6e-06\",\"load_best_model_at_end\":\"True\",\"logging_first_step\":\"False\",\"logging_nan_inf_filter\":\"True\",\"logging_steps\":\"10\",\"lr_scheduler_type\":\"constant_with_warmup\",\"max_grad_norm\":\"1.0\",\"max_input_length\":\"-1\",\"max_steps\":\"-1\",\"max_train_samples\":\"-1\",\"max_val_samples\":\"-1\",\"per_device_eval_batch_size\":\"8\",\"per_device_train_batch_size\":\"4\",\"preprocessing_num_workers\":\"None\",\"save_steps\":\"500\",\"save_strategy\":\"steps\",\"save_total_limit\":\"1\",\"seed\":\"10\",\"train_data_split_seed\":\"0\",\"train_from_scratch\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_ratio\":\"0.1\",\"warmup_steps\":\"0\",\"weight_decay\":\"0.2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3dn.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3dn.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3dn.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3dn.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3dn.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.999\",\"adam_epsilon\":\"1e-08\",\"auto_find_batch_size\":\"False\",\"bf16\":\"False\",\"dataloader_drop_last\":\"False\",\"dataloader_num_workers\":\"0\",\"early_stopping_patience\":\"3\",\"early_stopping_threshold\":\"0.0\",\"epoch\":\"3\",\"eval_accumulation_steps\":\"None\",\"eval_steps\":\"20\",\"evaluation_strategy\":\"steps\",\"fp16\":\"True\",\"gradient_accumulation_steps\":\"2\",\"gradient_checkpointing\":\"True\",\"instruction_tuned\":false,\"label_smoothing_factor\":\"0\",\"learning_rate\":\"6e-06\",\"load_best_model_at_end\":\"True\",\"logging_first_step\":\"False\",\"logging_nan_inf_filter\":\"True\",\"logging_steps\":\"10\",\"lr_scheduler_type\":\"constant_with_warmup\",\"max_grad_norm\":\"1.0\",\"max_input_length\":\"-1\",\"max_steps\":\"-1\",\"max_train_samples\":\"-1\",\"max_val_samples\":\"-1\",\"per_device_eval_batch_size\":\"8\",\"per_device_train_batch_size\":\"4\",\"preprocessing_num_workers\":\"None\",\"save_steps\":\"500\",\"save_strategy\":\"steps\",\"save_total_limit\":\"1\",\"seed\":\"10\",\"train_data_split_seed\":\"0\",\"train_from_scratch\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_ratio\":\"0.1\",\"warmup_steps\":\"0\",\"weight_decay\":\"0.2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3dn.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"ssides-hugging-face-huggingface-textgen-2023-08-04-16-25-01-097\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3dn.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3dn.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--adam_beta1\",\"0.9\",\"--adam_beta2\",\"0.999\",\"--adam_epsilon\",\"1e-08\",\"--auto_find_batch_size\",\"False\",\"--bf16\",\"False\",\"--dataloader_drop_last\",\"False\",\"--dataloader_num_workers\",\"0\",\"--early_stopping_patience\",\"3\",\"--early_stopping_threshold\",\"0.0\",\"--epoch\",\"3\",\"--eval_accumulation_steps\",\"None\",\"--eval_steps\",\"20\",\"--evaluation_strategy\",\"steps\",\"--fp16\",\"True\",\"--gradient_accumulation_steps\",\"2\",\"--gradient_checkpointing\",\"True\",\"--instruction_tuned\",\"False\",\"--label_smoothing_factor\",\"0\",\"--learning_rate\",\"6e-06\",\"--load_best_model_at_end\",\"True\",\"--logging_first_step\",\"False\",\"--logging_nan_inf_filter\",\"True\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"constant_with_warmup\",\"--max_grad_norm\",\"1.0\",\"--max_input_length\",\"-1\",\"--max_steps\",\"-1\",\"--max_train_samples\",\"-1\",\"--max_val_samples\",\"-1\",\"--per_device_eval_batch_size\",\"8\",\"--per_device_train_batch_size\",\"4\",\"--preprocessing_num_workers\",\"None\",\"--save_steps\",\"500\",\"--save_strategy\",\"steps\",\"--save_total_limit\",\"1\",\"--seed\",\"10\",\"--train_data_split_seed\",\"0\",\"--train_from_scratch\",\"False\",\"--validation_split_ratio\",\"0.2\",\"--warmup_ratio\",\"0.1\",\"--warmup_steps\",\"0\",\"--weight_decay\",\"0.2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_BETA1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_BETA2=0.999\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_EPSILON=1e-08\u001b[0m\n",
      "\u001b[34mSM_HP_AUTO_FIND_BATCH_SIZE=False\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=False\u001b[0m\n",
      "\u001b[34mSM_HP_DATALOADER_DROP_LAST=False\u001b[0m\n",
      "\u001b[34mSM_HP_DATALOADER_NUM_WORKERS=0\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_PATIENCE=3\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_THRESHOLD=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=3\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_ACCUMULATION_STEPS=None\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_STEPS=20\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_STRATEGY=steps\u001b[0m\n",
      "\u001b[34mSM_HP_FP16=True\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=True\u001b[0m\n",
      "\u001b[34mSM_HP_INSTRUCTION_TUNED=false\u001b[0m\n",
      "\u001b[34mSM_HP_LABEL_SMOOTHING_FACTOR=0\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=6e-06\u001b[0m\n",
      "\u001b[34mSM_HP_LOAD_BEST_MODEL_AT_END=True\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_FIRST_STEP=False\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_NAN_INF_FILTER=True\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=constant_with_warmup\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_INPUT_LENGTH=-1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_STEPS=-1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TRAIN_SAMPLES=-1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_VAL_SAMPLES=-1\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_PREPROCESSING_NUM_WORKERS=None\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STEPS=500\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=steps\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=1\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=10\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_DATA_SPLIT_SEED=0\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FROM_SCRATCH=False\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_SPLIT_RATIO=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=0\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 transfer_learning.py --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-08 --auto_find_batch_size False --bf16 False --dataloader_drop_last False --dataloader_num_workers 0 --early_stopping_patience 3 --early_stopping_threshold 0.0 --epoch 3 --eval_accumulation_steps None --eval_steps 20 --evaluation_strategy steps --fp16 True --gradient_accumulation_steps 2 --gradient_checkpointing True --instruction_tuned False --label_smoothing_factor 0 --learning_rate 6e-06 --load_best_model_at_end True --logging_first_step False --logging_nan_inf_filter True --logging_steps 10 --lr_scheduler_type constant_with_warmup --max_grad_norm 1.0 --max_input_length -1 --max_steps -1 --max_train_samples -1 --max_val_samples -1 --per_device_eval_batch_size 8 --per_device_train_batch_size 4 --preprocessing_num_workers None --save_steps 500 --save_strategy steps --save_total_limit 1 --seed 10 --train_data_split_seed 0 --train_from_scratch False --validation_split_ratio 0.2 --warmup_ratio 0.1 --warmup_steps 0 --weight_decay 0.2\u001b[0m\n",
      "\u001b[34m2023-08-04 16:38:50,646 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mINFO:root:Running training scripts with arguments: Namespace(model_dir='/opt/ml/model', train=None, train_alt='/opt/ml/input/data/train', validation=None, hosts=['algo-1'], num_gpus=8, current_host='algo-1', pretrained_model='/opt/ml/input/data/model', instruction_tuned='False', train_from_scratch='False', fp16='True', bf16='False', evaluation_strategy='steps', eval_steps=20, epoch=3, gradient_accumulation_steps=2, per_device_train_batch_size=4, per_device_eval_batch_size=8, logging_steps=10, warmup_ratio=0.1, learning_rate=6e-06, weight_decay=0.2, load_best_model_at_end='True', max_train_samples=-1, max_val_samples=-1, seed=10, max_input_length=-1, validation_split_ratio=0.2, train_data_split_seed=0, preprocessing_num_workers=None, max_steps=-1, gradient_checkpointing='True', early_stopping_patience=3, early_stopping_threshold=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, label_smoothing_factor=0.0, logging_strategy='steps', logging_first_step='False', logging_nan_inf_filter='True', save_strategy='steps', save_steps=500, save_total_limit=1, dataloader_drop_last='False', dataloader_num_workers=0, eval_accumulation_steps=None, auto_find_batch_size='False', lr_scheduler_type='constant_with_warmup', warmup_steps=0).\u001b[0m\n",
      "\u001b[34mINFO:root:Ignoring unrecognized arguments: [].\u001b[0m\n",
      "\u001b[34mINFO:root:Identify file serving.properties in the un-tar directory /tmp. Copying it over to /opt/ml/model for model deployment after training is finished.\u001b[0m\n",
      "\u001b[34mINFO:root:Parameter 'instruction_tuned' is identified as 'False'. Domain adaption fine-tuning will be started.\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:45,848] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:45,902] [INFO] [runner.py:555:main] cmd = /opt/conda/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /opt/conda/lib/python3.10/site-packages/sagemaker_jumpstart_huggingface_script_utilities/fine_tuning/run_clm.py --deepspeed ds_config.json --model_name_or_path /tmp --train_file /opt/ml/input/data/train --do_train --output_dir /opt/ml/model --num_train_epochs 3 --gradient_accumulation_steps 2 --per_device_train_batch_size 4 --per_device_eval_batch_size 8 --logging_steps 10 --warmup_ratio 0.1 --learning_rate 6e-06 --weight_decay 0.2 --seed 10 --max_input_length -1 --validation_split_ratio 0.2 --train_data_split_seed 0 --max_steps -1 --early_stopping_patience 3 --early_stopping_threshold 0.0 --adam_beta1 0.9 --adam_beta2 0.999 --max_grad_norm 1.0 --label_smoothing_factor 0.0 --logging_strategy steps --save_strategy steps --save_steps 500 --dataloader_num_workers 0 --lr_scheduler_type constant_with_warmup --warmup_steps 0 --evaluation_strategy steps --eval_steps 20 --load_best_model_at_end --fp16 --gradient_checkpointing --save_total_limit 1\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:138:main] 0 NCCL_DEBUG=WARN\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:138:main] 0 NCCL_SOCKET_IFNAME=eth0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:138:main] 0 NCCL_IB_DISABLE=1\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.16.2\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:163:main] dist_world_size=8\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:48,060] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,391] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,436] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,436] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,468] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,468] [INFO] [comm.py:594:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:51,469] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=ds_config.json,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_steps=20,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=steps,\u001b[0m\n",
      "\u001b[34mfp16=True,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=2,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=True,\u001b[0m\n",
      "\u001b[34mgreater_is_better=False,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=6e-06,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=0,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=warning,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/runs/Aug04_16-41-51_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=10,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=constant_with_warmup,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=loss,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=3.0,\u001b[0m\n",
      "\u001b[34moptim=adamw_hf,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=4,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=['tensorboard'],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_safetensors=False,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=steps,\u001b[0m\n",
      "\u001b[34msave_total_limit=1,\u001b[0m\n",
      "\u001b[34mseed=10,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.1,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.2,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m08/04/2023 16:41:54 - WARNING - __main__ -   Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file vocab.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file vocab.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file merges.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file merges.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file added_tokens.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file added_tokens.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1807] 2023-08-04 16:41:54,280 >> loading file tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:666] 2023-08-04 16:41:54,357 >> loading configuration file /tmp/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:666] 2023-08-04 16:41:54,357 >> loading configuration file /tmp/config.json\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,370] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,370] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:720] 2023-08-04 16:41:54,374 >> Model config GPTJConfig {\n",
      "  \"_name_or_path\": \"/tmp\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTJForCausalLM\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gptj\",\n",
      "  \"n_embd\": 4096,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 28,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rotary\": true,\n",
      "  \"rotary_dim\": 64,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 1.0\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50400\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:720] 2023-08-04 16:41:54,374 >> Model config GPTJConfig {\n",
      "  \"_name_or_path\": \"/tmp\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTJForCausalLM\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gptj\",\n",
      "  \"n_embd\": 4096,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 28,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rotary\": true,\n",
      "  \"rotary_dim\": 64,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 1.0\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50400\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,379] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,381] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,383] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,387] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2531] 2023-08-04 16:41:54,390 >> loading weights file /tmp/pytorch_model.bin.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2531] 2023-08-04 16:41:54,390 >> loading weights file /tmp/pytorch_model.bin.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2623] 2023-08-04 16:41:54,390 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2623] 2023-08-04 16:41:54,390 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,391] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:41:54,391] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:575] 2023-08-04 16:41:54,394 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"use_cache\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:575] 2023-08-04 16:41:54,394 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"use_cache\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mNCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:42:04,569] [INFO] [partition_parameters.py:454:__exit__] finished initializing model with 6.05B parameters\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:16,  8.13s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:16,  8.16s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.57s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.60s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.60s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.60s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.61s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:16<00:08,  8.40s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:16<00:08,  8.41s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.57s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.58s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.58s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.58s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.59s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.59s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.01s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.02s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.53s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.08s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.09s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.09s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.09s/it]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3190] 2023-08-04 16:42:25,882 >> All model checkpoint weights were used when initializing GPTJForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3190] 2023-08-04 16:42:25,882 >> All model checkpoint weights were used when initializing GPTJForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3198] 2023-08-04 16:42:25,882 >> All the weights of GPTJForCausalLM were initialized from the model checkpoint at /tmp.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPTJForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3198] 2023-08-04 16:42:25,882 >> All the weights of GPTJForCausalLM were initialized from the model checkpoint at /tmp.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPTJForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2839] 2023-08-04 16:42:25,885 >> Generation config file not found, using a generation config created from the model config.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2839] 2023-08-04 16:42:25,885 >> Generation config file not found, using a generation config created from the model config.\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.09s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  6.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.09s/it]\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 1/1 [00:00<00:00, 9098.27it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 1/1 [00:00<00:00, 1338.75it/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 56084 examples [00:00, 509779.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 111169 examples [00:00, 514934.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 167126 examples [00:00, 469485.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 223072 examples [00:00, 485257.56 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 278693 examples [00:00, 496343.92 examples/s]\u001b[0m\n",
      "\u001b[34mDataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 223.36it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 242.35it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 251.16it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 217.10it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 238.27it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 227.79it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 138.98it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - datasets.builder -   Found cached dataset text (/root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]#015Running tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 120.17it/s]\u001b[0m\n",
      "\u001b[34mThe tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m08/04/2023 16:42:26 - WARNING - sagemaker_jumpstart_huggingface_script_utilities.fine_tuning.data_preprocessor -   The tokenizer picked has a `model_max_length` (2048) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1000/311570 [00:00<00:38, 8082.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1000/311570 [00:00<00:41, 7489.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1000/311570 [00:00<00:33, 9194.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1000/311570 [00:00<00:45, 6898.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 2000/311570 [00:00<00:26, 11484.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 2000/311570 [00:00<00:25, 11967.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 2000/311570 [00:00<00:30, 10055.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1000/311570 [00:00<00:59, 5219.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 3000/311570 [00:00<00:30, 10091.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 3000/311570 [00:00<00:31, 9730.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|▏         | 4000/311570 [00:00<00:24, 12650.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|▏         | 4000/311570 [00:00<00:23, 12965.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 3000/311570 [00:00<00:28, 10904.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 3000/311570 [00:00<00:30, 10241.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|▏         | 4000/311570 [00:00<00:23, 13358.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 5000/311570 [00:00<00:24, 12695.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 3000/311570 [00:00<00:39, 7817.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 5000/311570 [00:00<00:28, 10805.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 6000/311570 [00:00<00:24, 12618.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 6000/311570 [00:00<00:24, 12615.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 5000/311570 [00:00<00:27, 11218.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 6000/311570 [00:00<00:25, 11909.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 5000/311570 [00:00<00:29, 10541.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|▏         | 4000/311570 [00:00<00:37, 8289.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 7000/311570 [00:00<00:25, 12145.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 7000/311570 [00:00<00:25, 11999.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 8000/311570 [00:00<00:24, 12549.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 7000/311570 [00:00<00:27, 11080.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 8000/311570 [00:00<00:25, 11766.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 7000/311570 [00:00<00:28, 10798.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 8000/311570 [00:00<00:26, 11376.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 6000/311570 [00:00<00:30, 9971.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 9000/311570 [00:00<00:26, 11580.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 9000/311570 [00:00<00:25, 11864.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 10000/311570 [00:00<00:23, 12878.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 8000/311570 [00:00<00:26, 11478.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 9000/311570 [00:00<00:26, 11565.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 10000/311570 [00:00<00:26, 11505.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 9000/311570 [00:00<00:27, 11009.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 10000/311570 [00:00<00:26, 11353.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▎         | 11000/311570 [00:00<00:25, 11661.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 10000/311570 [00:00<00:22, 13398.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▎         | 11000/311570 [00:00<00:25, 11579.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 12000/311570 [00:00<00:25, 11943.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▎         | 11000/311570 [00:00<00:25, 11645.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 12000/311570 [00:01<00:25, 11531.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 12000/311570 [00:01<00:25, 11603.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▎         | 11000/311570 [00:00<00:26, 11262.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 12000/311570 [00:01<00:22, 13047.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 14000/311570 [00:01<00:22, 12986.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 13000/311570 [00:01<00:27, 10969.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 13000/311570 [00:01<00:27, 11025.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 13000/311570 [00:01<00:24, 12377.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 14000/311570 [00:01<00:24, 12058.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 13000/311570 [00:01<00:25, 11719.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 14000/311570 [00:01<00:25, 11790.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 16000/311570 [00:01<00:23, 12849.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 14000/311570 [00:01<00:24, 12148.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▍         | 15000/311570 [00:01<00:23, 12535.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▍         | 15000/311570 [00:01<00:26, 11103.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▍         | 15000/311570 [00:01<00:26, 11237.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 16000/311570 [00:01<00:23, 12510.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 16000/311570 [00:01<00:25, 11580.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▍         | 15000/311570 [00:01<00:26, 11217.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 18000/311570 [00:01<00:21, 13852.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 16000/311570 [00:01<00:24, 12190.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 17000/311570 [00:01<00:23, 12748.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 17000/311570 [00:01<00:24, 11913.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 18000/311570 [00:01<00:22, 13342.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 17000/311570 [00:01<00:25, 11602.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 18000/311570 [00:01<00:23, 12591.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 17000/311570 [00:01<00:24, 11989.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▋         | 20000/311570 [00:01<00:20, 13885.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 19000/311570 [00:01<00:23, 12448.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 19000/311570 [00:01<00:22, 12730.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 19000/311570 [00:01<00:22, 12889.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▋         | 20000/311570 [00:01<00:22, 12910.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 18000/311570 [00:01<00:24, 11983.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▋         | 20000/311570 [00:01<00:21, 13409.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▌         | 19000/311570 [00:01<00:23, 12243.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 22000/311570 [00:01<00:22, 12864.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 21000/311570 [00:01<00:22, 12665.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▋         | 20000/311570 [00:01<00:23, 12672.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 21000/311570 [00:01<00:23, 12351.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 22000/311570 [00:01<00:21, 13677.20 examples/s]#015Running tokenizer on dataset:   7%|▋         | 22000/311570 [00:01<00:22, 13088.84 examples/s]#015Running tokenizer on dataset:   7%|▋         | 21000/311570 [00:01<00:23, 12569.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 21000/311570 [00:01<00:23, 12358.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 24000/311570 [00:01<00:21, 13453.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 23000/311570 [00:01<00:22, 12784.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 22000/311570 [00:01<00:22, 12832.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 24000/311570 [00:01<00:21, 13617.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 23000/311570 [00:01<00:22, 13007.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 24000/311570 [00:01<00:21, 13128.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 23000/311570 [00:01<00:23, 12398.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 26000/311570 [00:01<00:21, 13546.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 23000/311570 [00:01<00:23, 12382.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 25000/311570 [00:02<00:21, 13032.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 26000/311570 [00:02<00:21, 13287.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 25000/311570 [00:02<00:22, 12603.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 24000/311570 [00:02<00:22, 12671.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 25000/311570 [00:02<00:22, 12788.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 26000/311570 [00:02<00:22, 12558.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 25000/311570 [00:02<00:22, 12867.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 28000/311570 [00:02<00:21, 13393.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▊         | 27000/311570 [00:02<00:21, 13369.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▊         | 27000/311570 [00:02<00:21, 13191.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 26000/311570 [00:02<00:21, 13232.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 28000/311570 [00:02<00:20, 13673.43 examples/s]#015Running tokenizer on dataset:   9%|▉         | 28000/311570 [00:02<00:21, 13487.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▊         | 27000/311570 [00:02<00:21, 13048.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 28000/311570 [00:02<00:21, 13048.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 28000/311570 [00:02<00:20, 13771.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:18, 15414.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:26, 10696.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 29000/311570 [00:02<00:29, 9624.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 34000/311570 [00:02<00:16, 16557.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 29000/311570 [00:02<00:30, 9215.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:27, 10192.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 30000/311570 [00:02<00:32, 8675.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 33000/311570 [00:02<00:23, 11720.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 29000/311570 [00:02<00:32, 8603.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:26, 10535.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:25, 10839.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 36000/311570 [00:02<00:17, 15720.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:28, 10009.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 33000/311570 [00:02<00:24, 11263.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 32000/311570 [00:02<00:28, 9843.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 35000/311570 [00:02<00:24, 11342.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 33000/311570 [00:02<00:24, 11337.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 33000/311570 [00:02<00:24, 11469.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 33000/311570 [00:02<00:25, 11123.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 31000/311570 [00:02<00:30, 9180.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 35000/311570 [00:02<00:23, 11693.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 34000/311570 [00:02<00:26, 10632.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 37000/311570 [00:02<00:22, 11950.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 35000/311570 [00:02<00:22, 12286.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 35000/311570 [00:03<00:23, 11727.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 35000/311570 [00:03<00:23, 11529.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 33000/311570 [00:03<00:27, 10035.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 37000/311570 [00:03<00:22, 12239.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 36000/311570 [00:03<00:24, 11370.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 37000/311570 [00:03<00:20, 13330.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 39000/311570 [00:03<00:22, 12218.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 37000/311570 [00:03<00:21, 12763.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 37000/311570 [00:03<00:21, 12892.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 39000/311570 [00:03<00:20, 13166.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 35000/311570 [00:03<00:25, 10986.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 38000/311570 [00:03<00:21, 12508.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 38000/311570 [00:03<00:30, 9108.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 41000/311570 [00:03<00:20, 12919.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 39000/311570 [00:03<00:20, 13103.80 examples/s]#015Running tokenizer on dataset:  13%|█▎        | 39000/311570 [00:03<00:20, 13612.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 41000/311570 [00:03<00:19, 14226.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 39000/311570 [00:03<00:21, 12767.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 40000/311570 [00:03<00:20, 13262.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 40000/311570 [00:03<00:26, 10167.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 37000/311570 [00:03<00:24, 11432.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 43000/311570 [00:03<00:20, 13409.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 41000/311570 [00:03<00:20, 13299.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 41000/311570 [00:03<00:20, 13457.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 41000/311570 [00:03<00:20, 13495.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 43000/311570 [00:03<00:18, 14297.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 42000/311570 [00:03<00:20, 13069.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 39000/311570 [00:03<00:22, 11989.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 42000/311570 [00:03<00:24, 10890.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 45000/311570 [00:03<00:18, 14191.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 43000/311570 [00:03<00:19, 13481.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 43000/311570 [00:03<00:20, 12847.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▍        | 46000/311570 [00:03<00:18, 14128.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 43000/311570 [00:03<00:21, 12495.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 44000/311570 [00:03<00:22, 11686.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 41000/311570 [00:03<00:21, 12560.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 44000/311570 [00:03<00:21, 12643.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 48000/311570 [00:03<00:18, 14000.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 45000/311570 [00:03<00:20, 12957.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 45000/311570 [00:03<00:20, 13001.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 47000/311570 [00:03<00:20, 12872.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 43000/311570 [00:03<00:20, 13349.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 45000/311570 [00:03<00:21, 12291.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▍        | 46000/311570 [00:03<00:21, 12500.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▍        | 46000/311570 [00:03<00:20, 12783.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 50000/311570 [00:03<00:18, 14439.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 47000/311570 [00:03<00:20, 13133.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 47000/311570 [00:03<00:20, 12649.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 48000/311570 [00:03<00:20, 12787.30 examples/s]#015Running tokenizer on dataset:  15%|█▌        | 47000/311570 [00:03<00:20, 12605.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 45000/311570 [00:03<00:20, 13128.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 49000/311570 [00:03<00:20, 12689.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 48000/311570 [00:03<00:19, 13186.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 49000/311570 [00:04<00:18, 14014.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 52000/311570 [00:04<00:18, 14277.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▋        | 51000/311570 [00:04<00:19, 13446.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 47000/311570 [00:04<00:20, 13216.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 50000/311570 [00:04<00:20, 12776.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 49000/311570 [00:04<00:20, 12562.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 49000/311570 [00:04<00:21, 12257.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 50000/311570 [00:04<00:19, 13586.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▋        | 51000/311570 [00:04<00:18, 14134.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 54000/311570 [00:04<00:17, 14335.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 53000/311570 [00:04<00:17, 14828.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▋        | 51000/311570 [00:04<00:19, 13138.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▋        | 51000/311570 [00:04<00:20, 12931.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 52000/311570 [00:04<00:19, 12983.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 52000/311570 [00:04<00:18, 13995.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 50000/311570 [00:04<00:17, 15021.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 56000/311570 [00:04<00:17, 14278.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 53000/311570 [00:04<00:18, 13928.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 55000/311570 [00:04<00:17, 14412.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 54000/311570 [00:04<00:19, 13233.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 53000/311570 [00:04<00:19, 13045.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 54000/311570 [00:04<00:18, 13904.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 52000/311570 [00:04<00:17, 14652.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 53000/311570 [00:04<00:20, 12694.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 55000/311570 [00:04<00:18, 13812.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 55000/311570 [00:04<00:18, 13759.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 56000/311570 [00:04<00:18, 13727.43 examples/s]#015Running tokenizer on dataset:  18%|█▊        | 55000/311570 [00:04<00:19, 13268.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 54000/311570 [00:04<00:17, 14356.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 56000/311570 [00:04<00:19, 13026.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 56000/311570 [00:04<00:17, 14905.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 59000/311570 [00:04<00:16, 14926.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 57000/311570 [00:04<00:26, 9520.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▊        | 58000/311570 [00:04<00:27, 9084.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 59000/311570 [00:04<00:22, 11246.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 61000/311570 [00:04<00:15, 15858.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 57000/311570 [00:04<00:24, 10424.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 61000/311570 [00:04<00:21, 11528.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 57000/311570 [00:04<00:29, 8593.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 61000/311570 [00:04<00:20, 12254.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 63000/311570 [00:04<00:16, 15451.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 57000/311570 [00:04<00:28, 8787.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▊        | 58000/311570 [00:04<00:28, 8763.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 59000/311570 [00:04<00:22, 11193.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 59000/311570 [00:05<00:25, 10042.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 63000/311570 [00:05<00:21, 11622.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 65000/311570 [00:05<00:15, 15802.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 63000/311570 [00:05<00:19, 12631.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 60000/311570 [00:05<00:25, 9870.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 59000/311570 [00:05<00:26, 9656.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 61000/311570 [00:05<00:21, 11853.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▊        | 58000/311570 [00:05<00:28, 8881.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 61000/311570 [00:05<00:23, 10791.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 65000/311570 [00:05<00:19, 12367.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 67000/311570 [00:05<00:16, 14575.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 61000/311570 [00:05<00:23, 10707.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 66000/311570 [00:05<00:17, 13835.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 63000/311570 [00:05<00:20, 11963.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 62000/311570 [00:05<00:24, 10281.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 60000/311570 [00:05<00:27, 9227.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 67000/311570 [00:05<00:19, 12582.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 63000/311570 [00:05<00:21, 11324.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 69000/311570 [00:05<00:17, 14064.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 64000/311570 [00:05<00:21, 11459.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 63000/311570 [00:05<00:22, 11048.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 68000/311570 [00:05<00:17, 13659.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 65000/311570 [00:05<00:19, 12443.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 62000/311570 [00:05<00:24, 10020.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 69000/311570 [00:05<00:19, 12693.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 65000/311570 [00:05<00:21, 11741.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 65000/311570 [00:05<00:20, 11862.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 70000/311570 [00:05<00:17, 13849.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 66000/311570 [00:05<00:21, 11576.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 64000/311570 [00:05<00:21, 11439.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 67000/311570 [00:05<00:19, 12631.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 68000/311570 [00:05<00:18, 13230.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 71000/311570 [00:05<00:18, 13063.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 67000/311570 [00:05<00:19, 12745.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 72000/311570 [00:05<00:16, 14228.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 68000/311570 [00:05<00:18, 13013.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 66000/311570 [00:05<00:18, 13015.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 71000/311570 [00:05<00:24, 9801.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 70000/311570 [00:05<00:17, 13502.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 73000/311570 [00:05<00:17, 13366.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 69000/311570 [00:05<00:19, 12245.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 69000/311570 [00:05<00:18, 13012.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 70000/311570 [00:05<00:18, 12848.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 73000/311570 [00:05<00:21, 11120.41 examples/s]#015Running tokenizer on dataset:  24%|██▍       | 74000/311570 [00:05<00:17, 13449.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 68000/311570 [00:05<00:19, 12623.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 71000/311570 [00:05<00:18, 12876.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 75000/311570 [00:05<00:18, 13000.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 72000/311570 [00:05<00:18, 13000.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 71000/311570 [00:05<00:16, 14413.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 70000/311570 [00:05<00:18, 12891.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 72000/311570 [00:05<00:18, 12795.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 76000/311570 [00:05<00:17, 13387.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 75000/311570 [00:06<00:20, 11671.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▍       | 77000/311570 [00:06<00:17, 13433.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 73000/311570 [00:06<00:16, 14495.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 73000/311570 [00:06<00:18, 13138.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 74000/311570 [00:06<00:17, 13315.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 78000/311570 [00:06<00:17, 13662.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▍       | 77000/311570 [00:06<00:19, 12231.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 74000/311570 [00:06<00:18, 13032.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 72000/311570 [00:06<00:18, 13069.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 75000/311570 [00:06<00:16, 14178.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 75000/311570 [00:06<00:17, 13353.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 79000/311570 [00:06<00:17, 13343.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 76000/311570 [00:06<00:17, 13439.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 80000/311570 [00:06<00:16, 13699.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▍       | 77000/311570 [00:06<00:17, 13486.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 74000/311570 [00:06<00:17, 13418.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 79000/311570 [00:06<00:18, 12732.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▍       | 77000/311570 [00:06<00:17, 13711.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▍       | 77000/311570 [00:06<00:16, 14178.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 81000/311570 [00:06<00:17, 13320.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 78000/311570 [00:06<00:17, 13594.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 76000/311570 [00:06<00:17, 13602.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 81000/311570 [00:06<00:17, 13118.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 79000/311570 [00:06<00:17, 13450.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▋       | 82000/311570 [00:06<00:17, 13018.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 79000/311570 [00:06<00:17, 13457.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 79000/311570 [00:06<00:17, 13335.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 83000/311570 [00:06<00:17, 13169.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 78000/311570 [00:06<00:17, 13694.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 80000/311570 [00:06<00:17, 13224.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 81000/311570 [00:06<00:17, 13208.71 examples/s]#015Running tokenizer on dataset:  27%|██▋       | 83000/311570 [00:06<00:17, 12745.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 81000/311570 [00:06<00:16, 14040.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 81000/311570 [00:06<00:17, 13552.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 83000/311570 [00:06<00:16, 14229.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 85000/311570 [00:06<00:16, 13577.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▋       | 82000/311570 [00:06<00:16, 13704.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 81000/311570 [00:06<00:15, 15117.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 83000/311570 [00:06<00:16, 14155.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 83000/311570 [00:06<00:15, 14409.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 87000/311570 [00:06<00:15, 14552.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 84000/311570 [00:06<00:26, 8662.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 85000/311570 [00:06<00:25, 8812.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 87000/311570 [00:06<00:20, 11155.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 84000/311570 [00:07<00:21, 10461.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 91000/311570 [00:07<00:12, 17082.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 85000/311570 [00:07<00:23, 9636.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 88000/311570 [00:07<00:20, 10921.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 85000/311570 [00:07<00:24, 9393.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 93000/311570 [00:07<00:13, 16097.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 86000/311570 [00:07<00:20, 11096.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▊       | 89000/311570 [00:07<00:19, 11437.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 86000/311570 [00:07<00:21, 10327.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 84000/311570 [00:07<00:22, 9904.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 90000/311570 [00:07<00:19, 11522.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 88000/311570 [00:07<00:19, 11433.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 87000/311570 [00:07<00:21, 10405.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 95000/311570 [00:07<00:14, 15091.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 88000/311570 [00:07<00:19, 11303.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 88000/311570 [00:07<00:19, 11663.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 91000/311570 [00:07<00:18, 11785.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 86000/311570 [00:07<00:20, 10844.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 92000/311570 [00:07<00:18, 11887.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▊       | 89000/311570 [00:07<00:18, 12023.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 90000/311570 [00:07<00:19, 11587.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 93000/311570 [00:07<00:17, 12607.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 90000/311570 [00:07<00:18, 11937.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 90000/311570 [00:07<00:18, 11971.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 97000/311570 [00:07<00:15, 13676.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 88000/311570 [00:07<00:19, 11477.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 94000/311570 [00:07<00:17, 12504.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 91000/311570 [00:07<00:18, 12203.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 92000/311570 [00:07<00:18, 12140.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 95000/311570 [00:07<00:16, 12967.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 92000/311570 [00:07<00:18, 12120.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 92000/311570 [00:07<00:18, 11808.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 96000/311570 [00:07<00:16, 13158.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 90000/311570 [00:07<00:19, 11600.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 93000/311570 [00:07<00:16, 12895.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 94000/311570 [00:07<00:17, 12464.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 97000/311570 [00:07<00:16, 13250.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 94000/311570 [00:07<00:17, 12755.76 examples/s]#015Running tokenizer on dataset:  30%|███       | 94000/311570 [00:07<00:17, 12488.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|██▉       | 92000/311570 [00:07<00:17, 12305.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 98000/311570 [00:07<00:16, 13241.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 95000/311570 [00:07<00:16, 13513.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 96000/311570 [00:07<00:17, 12324.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 99000/311570 [00:07<00:15, 13539.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 96000/311570 [00:07<00:15, 13811.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 96000/311570 [00:07<00:16, 12887.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 97000/311570 [00:07<00:15, 14064.68 examples/s]#015Running tokenizer on dataset:  30%|███       | 94000/311570 [00:07<00:17, 12449.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 100000/311570 [00:07<00:15, 13299.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 99000/311570 [00:08<00:26, 8115.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 101000/311570 [00:07<00:15, 13773.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 98000/311570 [00:08<00:15, 13745.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 99000/311570 [00:08<00:15, 13822.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 98000/311570 [00:08<00:16, 13005.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 102000/311570 [00:08<00:15, 13367.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███       | 96000/311570 [00:08<00:17, 12586.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 99000/311570 [00:08<00:16, 13189.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 101000/311570 [00:08<00:23, 9000.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 100000/311570 [00:08<00:15, 13911.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 103000/311570 [00:08<00:15, 13535.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 100000/311570 [00:08<00:15, 13822.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 101000/311570 [00:08<00:15, 13835.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 104000/311570 [00:08<00:15, 13335.81 examples/s]#015Running tokenizer on dataset:  32%|███▏      | 101000/311570 [00:08<00:15, 13900.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 98000/311570 [00:08<00:16, 12792.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 103000/311570 [00:08<00:20, 10182.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 102000/311570 [00:08<00:14, 14170.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▎      | 105000/311570 [00:08<00:15, 13484.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 103000/311570 [00:08<00:15, 13816.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 102000/311570 [00:08<00:16, 12514.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 100000/311570 [00:08<00:15, 13463.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 103000/311570 [00:08<00:14, 14118.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 106000/311570 [00:08<00:15, 13658.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▎      | 105000/311570 [00:08<00:18, 11448.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 104000/311570 [00:08<00:14, 13905.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 104000/311570 [00:08<00:15, 13289.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▎      | 105000/311570 [00:08<00:15, 13505.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 102000/311570 [00:08<00:15, 13783.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 108000/311570 [00:08<00:14, 13823.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▎      | 105000/311570 [00:08<00:14, 14012.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 108000/311570 [00:08<00:15, 13175.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 107000/311570 [00:08<00:17, 11611.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 106000/311570 [00:08<00:15, 13441.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 107000/311570 [00:08<00:15, 13109.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 106000/311570 [00:08<00:15, 12870.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▌      | 110000/311570 [00:08<00:14, 14081.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 107000/311570 [00:08<00:14, 13936.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▌      | 110000/311570 [00:08<00:14, 13718.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 104000/311570 [00:08<00:15, 13077.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 109000/311570 [00:08<00:16, 12378.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 108000/311570 [00:08<00:15, 13447.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 108000/311570 [00:08<00:15, 13219.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 109000/311570 [00:08<00:14, 13938.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 106000/311570 [00:08<00:14, 13746.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 111000/311570 [00:08<00:14, 13693.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 109000/311570 [00:08<00:15, 12721.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▌      | 110000/311570 [00:08<00:14, 14187.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▌      | 110000/311570 [00:08<00:14, 13975.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 108000/311570 [00:08<00:14, 14158.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▋      | 113000/311570 [00:08<00:14, 14064.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▋      | 113000/311570 [00:09<00:19, 10103.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 116000/311570 [00:09<00:12, 16269.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▋      | 113000/311570 [00:09<00:20, 9803.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 111000/311570 [00:09<00:21, 9359.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 111000/311570 [00:09<00:21, 9430.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 115000/311570 [00:09<00:17, 11511.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 112000/311570 [00:09<00:20, 9566.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 119000/311570 [00:09<00:11, 16883.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▋      | 113000/311570 [00:09<00:17, 11349.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 115000/311570 [00:09<00:18, 10670.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▋      | 113000/311570 [00:09<00:18, 10533.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 117000/311570 [00:09<00:15, 12377.22 examples/s]#015Running tokenizer on dataset:  37%|███▋      | 114000/311570 [00:09<00:16, 11638.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 111000/311570 [00:09<00:19, 10324.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 115000/311570 [00:09<00:16, 12198.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 117000/311570 [00:09<00:16, 11781.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 121000/311570 [00:09<00:12, 15472.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 114000/311570 [00:09<00:19, 10176.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 115000/311570 [00:09<00:17, 11400.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 116000/311570 [00:09<00:15, 12237.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 119000/311570 [00:09<00:15, 12350.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▋      | 113000/311570 [00:09<00:18, 11018.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 119000/311570 [00:09<00:15, 12402.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 117000/311570 [00:09<00:15, 12528.54 examples/s]#015Running tokenizer on dataset:  39%|███▉      | 123000/311570 [00:09<00:12, 15517.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 116000/311570 [00:09<00:17, 11450.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 117000/311570 [00:09<00:15, 12233.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 118000/311570 [00:09<00:15, 12825.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 115000/311570 [00:09<00:15, 12304.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 121000/311570 [00:09<00:15, 12480.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 121000/311570 [00:09<00:14, 12792.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 118000/311570 [00:09<00:16, 12083.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 119000/311570 [00:09<00:15, 12330.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 125000/311570 [00:09<00:13, 14007.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 119000/311570 [00:09<00:15, 12326.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 117000/311570 [00:09<00:15, 12822.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▊      | 120000/311570 [00:09<00:15, 12429.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 123000/311570 [00:09<00:14, 13054.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▊      | 120000/311570 [00:09<00:15, 12405.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|███▉      | 124000/311570 [00:09<00:12, 14480.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 121000/311570 [00:09<00:15, 12362.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 125000/311570 [00:09<00:13, 13925.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 119000/311570 [00:09<00:14, 13210.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 121000/311570 [00:09<00:14, 12804.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 122000/311570 [00:09<00:14, 12857.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 123000/311570 [00:10<00:13, 13647.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 126000/311570 [00:09<00:12, 14401.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 122000/311570 [00:10<00:14, 12661.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 123000/311570 [00:10<00:14, 13341.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 127000/311570 [00:10<00:13, 14028.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 121000/311570 [00:10<00:14, 13535.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|███▉      | 124000/311570 [00:10<00:13, 13572.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 125000/311570 [00:10<00:13, 13871.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|███▉      | 124000/311570 [00:10<00:14, 13395.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 128000/311570 [00:10<00:12, 14442.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 123000/311570 [00:10<00:13, 13780.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████▏     | 129000/311570 [00:10<00:12, 14092.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 128000/311570 [00:10<00:18, 9815.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 125000/311570 [00:10<00:13, 13455.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 126000/311570 [00:10<00:14, 12692.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 127000/311570 [00:10<00:13, 14040.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 126000/311570 [00:10<00:13, 13708.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 130000/311570 [00:10<00:12, 14428.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 127000/311570 [00:10<00:13, 13379.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 131000/311570 [00:10<00:13, 13611.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 130000/311570 [00:10<00:17, 10296.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 125000/311570 [00:10<00:14, 13079.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 128000/311570 [00:10<00:13, 13506.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 132000/311570 [00:10<00:12, 14260.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 128000/311570 [00:10<00:13, 13418.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████▏     | 129000/311570 [00:10<00:13, 13597.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████▏     | 129000/311570 [00:10<00:13, 13292.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 130000/311570 [00:10<00:13, 13726.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 132000/311570 [00:10<00:16, 11057.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 133000/311570 [00:10<00:13, 12974.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 127000/311570 [00:10<00:14, 12551.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 130000/311570 [00:10<00:13, 13329.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 131000/311570 [00:10<00:13, 13478.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 135000/311570 [00:10<00:11, 15499.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 135000/311570 [00:10<00:12, 13871.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 134000/311570 [00:10<00:15, 11824.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 132000/311570 [00:10<00:13, 13618.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 131000/311570 [00:10<00:13, 13051.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████▏     | 129000/311570 [00:10<00:13, 13212.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 137000/311570 [00:10<00:11, 14847.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 132000/311570 [00:10<00:13, 13050.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 133000/311570 [00:10<00:13, 13009.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 134000/311570 [00:10<00:12, 13857.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▎     | 136000/311570 [00:10<00:14, 12021.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 131000/311570 [00:10<00:13, 13600.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 137000/311570 [00:10<00:13, 13328.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 133000/311570 [00:10<00:13, 13130.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 134000/311570 [00:10<00:13, 13361.85 examples/s]#015Running tokenizer on dataset:  43%|████▎     | 135000/311570 [00:10<00:13, 13487.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 138000/311570 [00:10<00:13, 12442.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 135000/311570 [00:10<00:13, 13397.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 137000/311570 [00:10<00:11, 15391.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 133000/311570 [00:10<00:13, 13535.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▎     | 136000/311570 [00:11<00:12, 14226.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 137000/311570 [00:11<00:12, 13782.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 135000/311570 [00:11<00:12, 14316.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 137000/311570 [00:11<00:12, 13932.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 140000/311570 [00:11<00:13, 13103.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 139000/311570 [00:11<00:17, 9599.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 142000/311570 [00:11<00:12, 14075.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 137000/311570 [00:11<00:11, 14720.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 140000/311570 [00:11<00:17, 9956.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▌     | 141000/311570 [00:11<00:15, 11045.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 138000/311570 [00:11<00:16, 10309.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 142000/311570 [00:11<00:15, 11178.73 examples/s]#015Running tokenizer on dataset:  46%|████▌     | 144000/311570 [00:11<00:11, 14671.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 139000/311570 [00:11<00:16, 10227.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 140000/311570 [00:11<00:14, 11534.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 143000/311570 [00:11<00:14, 12027.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 144000/311570 [00:11<00:13, 12256.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 146000/311570 [00:11<00:11, 14469.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 142000/311570 [00:11<00:13, 12164.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▌     | 141000/311570 [00:11<00:15, 11147.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 139000/311570 [00:11<00:18, 9083.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 140000/311570 [00:11<00:16, 10618.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 145000/311570 [00:11<00:13, 12303.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 146000/311570 [00:11<00:12, 13289.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 139000/311570 [00:11<00:18, 9325.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 144000/311570 [00:11<00:13, 12384.83 examples/s]#015Running tokenizer on dataset:  46%|████▌     | 142000/311570 [00:11<00:14, 11669.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▌     | 141000/311570 [00:11<00:16, 10121.84 examples/s]#015Running tokenizer on dataset:  48%|████▊     | 148000/311570 [00:11<00:11, 13724.98 examples/s]#015Running tokenizer on dataset:  46%|████▌     | 143000/311570 [00:11<00:14, 11535.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 147000/311570 [00:11<00:13, 12576.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 148000/311570 [00:11<00:12, 13061.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▌     | 141000/311570 [00:11<00:16, 10459.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 150000/311570 [00:11<00:11, 14064.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 144000/311570 [00:11<00:13, 12285.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 145000/311570 [00:11<00:13, 12292.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 143000/311570 [00:11<00:15, 11024.98 examples/s]#015Running tokenizer on dataset:  47%|████▋     | 146000/311570 [00:11<00:13, 12715.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 150000/311570 [00:11<00:11, 13992.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 143000/311570 [00:11<00:13, 12122.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 149000/311570 [00:11<00:12, 13076.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 148000/311570 [00:11<00:12, 13278.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 146000/311570 [00:11<00:13, 12727.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 147000/311570 [00:11<00:12, 12693.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 145000/311570 [00:11<00:14, 11481.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 152000/311570 [00:11<00:12, 13277.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 151000/311570 [00:11<00:12, 13373.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 152000/311570 [00:11<00:11, 13814.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 145000/311570 [00:11<00:13, 12603.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 147000/311570 [00:12<00:12, 12719.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 148000/311570 [00:12<00:12, 13106.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 149000/311570 [00:12<00:12, 12946.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 150000/311570 [00:12<00:12, 13076.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 154000/311570 [00:12<00:11, 14105.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 153000/311570 [00:12<00:11, 13692.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 148000/311570 [00:12<00:12, 13363.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 150000/311570 [00:12<00:11, 13478.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 151000/311570 [00:12<00:11, 13552.50 examples/s]#015Running tokenizer on dataset:  49%|████▉     | 152000/311570 [00:12<00:11, 13481.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 149000/311570 [00:12<00:13, 12339.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 154000/311570 [00:12<00:16, 9826.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 156000/311570 [00:12<00:11, 13908.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|████▉     | 155000/311570 [00:12<00:12, 12854.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 150000/311570 [00:12<00:12, 13275.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 151000/311570 [00:12<00:12, 13172.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 152000/311570 [00:12<00:12, 13170.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 153000/311570 [00:12<00:11, 13225.33 examples/s]#015Running tokenizer on dataset:  49%|████▉     | 154000/311570 [00:12<00:11, 13348.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 156000/311570 [00:12<00:14, 10839.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 158000/311570 [00:12<00:11, 13515.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 157000/311570 [00:12<00:11, 13517.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 154000/311570 [00:12<00:11, 13307.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 156000/311570 [00:12<00:11, 13439.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|████▉     | 155000/311570 [00:12<00:11, 13350.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 153000/311570 [00:12<00:12, 12743.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 152000/311570 [00:12<00:12, 12659.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 159000/311570 [00:12<00:11, 12945.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████▏    | 160000/311570 [00:12<00:11, 13746.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 156000/311570 [00:12<00:11, 13561.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|████▉     | 155000/311570 [00:12<00:11, 13496.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 157000/311570 [00:12<00:11, 13388.30 examples/s]#015Running tokenizer on dataset:  51%|█████     | 158000/311570 [00:12<00:11, 13448.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 154000/311570 [00:12<00:11, 13398.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████▏    | 160000/311570 [00:12<00:11, 13514.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 162000/311570 [00:12<00:11, 13531.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 161000/311570 [00:12<00:11, 12789.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 156000/311570 [00:12<00:11, 13746.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 157000/311570 [00:12<00:11, 13632.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████▏    | 160000/311570 [00:12<00:11, 13668.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 158000/311570 [00:12<00:11, 13462.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 162000/311570 [00:12<00:10, 13819.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 159000/311570 [00:12<00:11, 13335.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 164000/311570 [00:12<00:11, 13331.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 163000/311570 [00:12<00:12, 12244.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████▏    | 160000/311570 [00:12<00:11, 13392.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 158000/311570 [00:12<00:11, 13039.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 162000/311570 [00:12<00:11, 13021.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 159000/311570 [00:12<00:11, 12806.81 examples/s]#015Running tokenizer on dataset:  53%|█████▎    | 164000/311570 [00:12<00:11, 13069.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 161000/311570 [00:12<00:11, 12919.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 165000/311570 [00:13<00:11, 12878.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████▏    | 160000/311570 [00:13<00:11, 13464.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 161000/311570 [00:13<00:11, 13480.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 164000/311570 [00:13<00:10, 13490.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 163000/311570 [00:13<00:10, 13520.37 examples/s]#015Running tokenizer on dataset:  52%|█████▏    | 163000/311570 [00:13<00:09, 15132.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▎    | 167000/311570 [00:13<00:10, 13771.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 163000/311570 [00:13<00:10, 13774.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 162000/311570 [00:13<00:10, 13724.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 166000/311570 [00:13<00:14, 10091.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 169000/311570 [00:13<00:10, 13771.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 164000/311570 [00:13<00:10, 13884.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▎    | 167000/311570 [00:13<00:15, 9037.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 169000/311570 [00:13<00:11, 12261.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▎    | 167000/311570 [00:13<00:12, 11168.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 171000/311570 [00:13<00:09, 14230.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 169000/311570 [00:13<00:13, 10411.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 165000/311570 [00:13<00:15, 9748.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 165000/311570 [00:13<00:17, 8434.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 173000/311570 [00:13<00:09, 15065.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 171000/311570 [00:13<00:10, 13103.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 169000/311570 [00:13<00:11, 12136.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 171000/311570 [00:13<00:12, 11271.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 165000/311570 [00:13<00:16, 8913.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▎    | 167000/311570 [00:13<00:14, 10258.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 171000/311570 [00:13<00:11, 12726.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 175000/311570 [00:13<00:09, 14177.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 166000/311570 [00:13<00:14, 9869.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 173000/311570 [00:13<00:11, 12583.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 168000/311570 [00:13<00:14, 10134.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 173000/311570 [00:13<00:12, 11313.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 169000/311570 [00:13<00:12, 11120.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▎    | 167000/311570 [00:13<00:15, 9536.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 168000/311570 [00:13<00:13, 10872.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:13<00:09, 14085.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 173000/311570 [00:13<00:11, 12556.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 175000/311570 [00:13<00:10, 12981.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 170000/311570 [00:13<00:12, 10988.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 175000/311570 [00:13<00:11, 11927.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 171000/311570 [00:13<00:12, 11534.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 169000/311570 [00:13<00:13, 10294.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 170000/311570 [00:13<00:12, 11636.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:09, 14059.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 175000/311570 [00:13<00:10, 12603.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:14<00:10, 13144.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▌    | 172000/311570 [00:14<00:11, 11790.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 171000/311570 [00:14<00:12, 11414.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▌    | 172000/311570 [00:14<00:10, 13029.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:14<00:11, 11649.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 173000/311570 [00:14<00:12, 11413.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:14<00:10, 13253.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 174000/311570 [00:14<00:11, 12017.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:10, 12366.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:09, 14135.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 173000/311570 [00:14<00:11, 11549.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 175000/311570 [00:14<00:11, 12196.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:11, 11780.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 174000/311570 [00:14<00:11, 12228.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:14<00:09, 13755.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 181000/311570 [00:14<00:10, 12817.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 181000/311570 [00:14<00:09, 14009.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 181000/311570 [00:14<00:10, 12806.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:14<00:10, 12888.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 175000/311570 [00:14<00:11, 12129.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 182000/311570 [00:14<00:12, 10178.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▋    | 176000/311570 [00:14<00:10, 13073.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:09, 13823.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▊    | 183000/311570 [00:14<00:09, 13036.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 177000/311570 [00:14<00:10, 12719.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▊    | 183000/311570 [00:14<00:09, 13871.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 178000/311570 [00:14<00:10, 13333.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:10, 13079.29 examples/s]#015Running tokenizer on dataset:  59%|█████▊    | 183000/311570 [00:14<00:09, 12991.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 184000/311570 [00:14<00:11, 10884.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 185000/311570 [00:14<00:09, 13560.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 181000/311570 [00:14<00:09, 13897.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|█████▉    | 186000/311570 [00:14<00:10, 11710.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 185000/311570 [00:14<00:09, 13902.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 180000/311570 [00:14<00:09, 13516.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 181000/311570 [00:14<00:09, 13280.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 185000/311570 [00:14<00:09, 13193.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 179000/311570 [00:14<00:10, 12731.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▊    | 183000/311570 [00:14<00:09, 13715.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 187000/311570 [00:14<00:09, 13353.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 187000/311570 [00:14<00:09, 13585.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▊    | 183000/311570 [00:14<00:09, 13564.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 181000/311570 [00:14<00:09, 13263.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 187000/311570 [00:14<00:08, 13885.89 examples/s]#015Running tokenizer on dataset:  60%|██████    | 188000/311570 [00:14<00:10, 12218.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 182000/311570 [00:14<00:09, 13419.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 189000/311570 [00:14<00:08, 13702.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 185000/311570 [00:14<00:09, 13868.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 190000/311570 [00:15<00:09, 12716.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 189000/311570 [00:14<00:09, 13583.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 184000/311570 [00:14<00:09, 13745.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 189000/311570 [00:14<00:08, 13827.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 185000/311570 [00:15<00:09, 13411.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▊    | 183000/311570 [00:15<00:10, 12525.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████▏   | 191000/311570 [00:15<00:08, 13447.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 187000/311570 [00:15<00:09, 13557.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 192000/311570 [00:15<00:08, 13399.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████▏   | 191000/311570 [00:15<00:09, 13289.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 187000/311570 [00:15<00:09, 13342.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|█████▉    | 186000/311570 [00:15<00:09, 13229.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████▏   | 191000/311570 [00:15<00:09, 12906.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 185000/311570 [00:15<00:10, 12547.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 189000/311570 [00:15<00:09, 13457.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 194000/311570 [00:15<00:08, 13986.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 188000/311570 [00:15<00:08, 13939.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 189000/311570 [00:15<00:08, 13757.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 187000/311570 [00:15<00:09, 13644.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████▏   | 191000/311570 [00:15<00:08, 13772.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 196000/311570 [00:15<00:07, 14733.35 examples/s]#015Running tokenizer on dataset:  62%|██████▏   | 193000/311570 [00:15<00:11, 10312.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 190000/311570 [00:15<00:08, 14459.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████▏   | 191000/311570 [00:15<00:08, 13586.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 189000/311570 [00:15<00:08, 13847.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 193000/311570 [00:15<00:11, 10125.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 195000/311570 [00:15<00:10, 11222.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▎   | 198000/311570 [00:15<00:07, 14234.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 193000/311570 [00:15<00:13, 9065.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████▏   | 191000/311570 [00:15<00:08, 14217.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 200000/311570 [00:15<00:07, 15009.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 195000/311570 [00:15<00:10, 10816.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 197000/311570 [00:15<00:09, 12349.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 196000/311570 [00:15<00:09, 12081.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 199000/311570 [00:15<00:08, 13774.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 197000/311570 [00:15<00:09, 12350.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▎   | 198000/311570 [00:15<00:08, 13505.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 202000/311570 [00:15<00:06, 15767.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 194000/311570 [00:15<00:11, 9837.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 193000/311570 [00:15<00:12, 9283.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 192000/311570 [00:15<00:13, 9166.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 201000/311570 [00:15<00:07, 14331.89 examples/s]#015Running tokenizer on dataset:  64%|██████▍   | 199000/311570 [00:15<00:08, 13227.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 200000/311570 [00:15<00:07, 14063.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 204000/311570 [00:15<00:06, 15782.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 194000/311570 [00:15<00:11, 10633.40 examples/s]#015Running tokenizer on dataset:  63%|██████▎   | 195000/311570 [00:15<00:10, 10718.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 196000/311570 [00:15<00:10, 10956.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 203000/311570 [00:16<00:07, 14416.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 193000/311570 [00:15<00:13, 8748.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 202000/311570 [00:15<00:07, 14123.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 206000/311570 [00:16<00:06, 15275.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 201000/311570 [00:15<00:08, 13415.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 197000/311570 [00:16<00:09, 11537.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▎   | 198000/311570 [00:16<00:09, 11665.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 196000/311570 [00:16<00:10, 11424.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 205000/311570 [00:16<00:07, 14813.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 195000/311570 [00:16<00:11, 10075.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 204000/311570 [00:16<00:07, 14532.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 203000/311570 [00:16<00:07, 14078.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 199000/311570 [00:16<00:09, 12403.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▎   | 198000/311570 [00:16<00:09, 12346.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 200000/311570 [00:16<00:09, 12315.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▋   | 207000/311570 [00:16<00:07, 14676.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 197000/311570 [00:16<00:10, 11111.63 examples/s]#015Running tokenizer on dataset:  66%|██████▌   | 205000/311570 [00:16<00:07, 14365.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 206000/311570 [00:16<00:07, 14517.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 202000/311570 [00:16<00:08, 13146.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 200000/311570 [00:16<00:08, 12857.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 201000/311570 [00:16<00:08, 12829.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 209000/311570 [00:16<00:07, 14374.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▋   | 207000/311570 [00:16<00:07, 14130.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 199000/311570 [00:16<00:09, 11740.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 208000/311570 [00:16<00:07, 14274.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 202000/311570 [00:16<00:08, 13039.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 203000/311570 [00:16<00:08, 13033.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 204000/311570 [00:16<00:08, 13017.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 209000/311570 [00:16<00:10, 9663.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 210000/311570 [00:16<00:07, 14104.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 201000/311570 [00:16<00:09, 12193.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 211000/311570 [00:16<00:07, 13991.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 209000/311570 [00:16<00:07, 13722.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 205000/311570 [00:16<00:08, 13302.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 211000/311570 [00:16<00:09, 10552.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 204000/311570 [00:16<00:08, 13172.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 206000/311570 [00:16<00:08, 12692.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 213000/311570 [00:16<00:07, 13841.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 211000/311570 [00:16<00:07, 13615.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 203000/311570 [00:16<00:08, 12369.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 212000/311570 [00:16<00:07, 13652.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 208000/311570 [00:16<00:07, 13404.29 examples/s]#015Running tokenizer on dataset:  66%|██████▌   | 206000/311570 [00:16<00:07, 13221.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 213000/311570 [00:16<00:08, 11186.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▋   | 207000/311570 [00:16<00:07, 13194.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 205000/311570 [00:16<00:08, 12950.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 213000/311570 [00:16<00:07, 13822.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 215000/311570 [00:16<00:07, 13416.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▊   | 214000/311570 [00:16<00:07, 12737.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 208000/311570 [00:16<00:07, 13475.99 examples/s]#015Running tokenizer on dataset:  67%|██████▋   | 209000/311570 [00:16<00:07, 13450.84 examples/s]#015Running tokenizer on dataset:  69%|██████▉   | 215000/311570 [00:16<00:08, 11809.41 examples/s]#015Running tokenizer on dataset:  67%|██████▋   | 210000/311570 [00:16<00:07, 13489.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▋   | 207000/311570 [00:16<00:07, 13089.53 examples/s]#015Running tokenizer on dataset:  70%|██████▉   | 217000/311570 [00:17<00:06, 13821.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 215000/311570 [00:16<00:07, 13673.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 216000/311570 [00:17<00:07, 13122.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 210000/311570 [00:17<00:07, 13459.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 211000/311570 [00:17<00:07, 12607.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 217000/311570 [00:17<00:08, 11463.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 212000/311570 [00:17<00:08, 12398.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 209000/311570 [00:17<00:07, 13163.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 217000/311570 [00:17<00:07, 13376.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 218000/311570 [00:17<00:07, 12772.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 212000/311570 [00:17<00:07, 13465.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 219000/311570 [00:17<00:07, 11656.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▊   | 214000/311570 [00:17<00:06, 14121.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▊   | 214000/311570 [00:17<00:07, 12245.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 211000/311570 [00:17<00:07, 13514.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▊   | 214000/311570 [00:17<00:06, 14395.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 216000/311570 [00:17<00:06, 13693.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 219000/311570 [00:17<00:10, 9108.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 216000/311570 [00:17<00:06, 14677.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 213000/311570 [00:17<00:06, 14489.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:17<00:07, 12332.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 216000/311570 [00:17<00:06, 14814.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:17<00:08, 10289.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 215000/311570 [00:17<00:06, 14814.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 218000/311570 [00:17<00:06, 14824.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 219000/311570 [00:17<00:10, 9198.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:17<00:06, 13397.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 218000/311570 [00:17<00:06, 13715.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 218000/311570 [00:17<00:06, 14237.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 220000/311570 [00:17<00:11, 8249.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:17<00:07, 11226.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:17<00:08, 10350.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 217000/311570 [00:17<00:06, 14574.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 226000/311570 [00:17<00:06, 14029.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 225000/311570 [00:17<00:07, 12181.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:17<00:08, 10636.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:17<00:07, 11450.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:17<00:08, 11202.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 225000/311570 [00:17<00:06, 12377.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 225000/311570 [00:17<00:07, 11547.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:17<00:05, 14307.24 examples/s]#015Running tokenizer on dataset:  73%|███████▎  | 227000/311570 [00:17<00:06, 12708.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:18<00:07, 12239.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:18<00:09, 9819.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 219000/311570 [00:18<00:09, 9645.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:18<00:06, 13108.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:05, 14112.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 227000/311570 [00:18<00:06, 12576.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:18<00:09, 9597.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 227000/311570 [00:18<00:07, 11916.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 221000/311570 [00:18<00:08, 11303.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:18<00:08, 10579.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 225000/311570 [00:18<00:07, 12331.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 223000/311570 [00:18<00:08, 10480.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:18<00:06, 12424.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:06, 13168.52 examples/s]#015Running tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:18<00:06, 12844.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:05, 13752.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 224000/311570 [00:18<00:06, 13622.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 227000/311570 [00:18<00:06, 12425.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 225000/311570 [00:18<00:07, 10864.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 225000/311570 [00:18<00:07, 11489.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:06, 13396.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:06, 12879.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:05, 13468.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:18<00:06, 13723.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 227000/311570 [00:18<00:06, 12373.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 226000/311570 [00:18<00:06, 13953.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:05, 13594.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:05, 13808.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 227000/311570 [00:18<00:06, 12135.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 235000/311570 [00:18<00:05, 13915.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 228000/311570 [00:18<00:05, 14389.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:18<00:06, 13103.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:05, 14058.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 229000/311570 [00:18<00:06, 12933.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 235000/311570 [00:18<00:05, 14242.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 237000/311570 [00:18<00:05, 14331.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 235000/311570 [00:18<00:05, 13877.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 230000/311570 [00:18<00:05, 14360.11 examples/s]#015Running tokenizer on dataset:  76%|███████▌  | 236000/311570 [00:18<00:07, 9786.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:06, 13403.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:05, 14097.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 231000/311570 [00:18<00:06, 13309.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 237000/311570 [00:18<00:05, 14205.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 239000/311570 [00:18<00:05, 14214.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 237000/311570 [00:18<00:05, 13807.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 235000/311570 [00:18<00:05, 14133.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▋  | 238000/311570 [00:18<00:06, 10562.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 232000/311570 [00:18<00:05, 14026.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:06, 12782.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 239000/311570 [00:18<00:05, 13809.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▍  | 233000/311570 [00:18<00:05, 13119.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 241000/311570 [00:18<00:05, 13848.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 237000/311570 [00:19<00:05, 13689.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 240000/311570 [00:18<00:05, 13717.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 234000/311570 [00:19<00:05, 13629.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 235000/311570 [00:19<00:05, 13370.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 240000/311570 [00:19<00:06, 10924.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 235000/311570 [00:19<00:06, 12596.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 243000/311570 [00:19<00:05, 13004.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 242000/311570 [00:19<00:04, 14601.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 242000/311570 [00:19<00:05, 12006.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 237000/311570 [00:19<00:05, 14001.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 239000/311570 [00:19<00:05, 12826.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 242000/311570 [00:19<00:05, 12952.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 236000/311570 [00:19<00:06, 12225.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▊  | 245000/311570 [00:19<00:04, 14098.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 244000/311570 [00:19<00:04, 14476.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 237000/311570 [00:19<00:05, 12651.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 244000/311570 [00:19<00:05, 12082.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 239000/311570 [00:19<00:05, 13365.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 244000/311570 [00:19<00:05, 13418.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 241000/311570 [00:19<00:05, 13197.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 239000/311570 [00:19<00:05, 13737.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 239000/311570 [00:19<00:05, 13143.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 246000/311570 [00:19<00:05, 12583.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 241000/311570 [00:19<00:05, 13597.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 243000/311570 [00:19<00:04, 13951.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 241000/311570 [00:19<00:04, 14424.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 241000/311570 [00:19<00:04, 14393.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 243000/311570 [00:19<00:04, 14023.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 248000/311570 [00:19<00:05, 11059.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▊  | 245000/311570 [00:19<00:04, 14087.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 248000/311570 [00:19<00:04, 12859.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 246000/311570 [00:19<00:06, 10219.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 243000/311570 [00:19<00:05, 13698.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 243000/311570 [00:19<00:04, 13755.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 250000/311570 [00:19<00:04, 13414.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 248000/311570 [00:19<00:05, 11422.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 250000/311570 [00:19<00:05, 11779.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 246000/311570 [00:19<00:07, 8541.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▊  | 245000/311570 [00:19<00:04, 14540.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▊  | 245000/311570 [00:19<00:04, 14423.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 250000/311570 [00:19<00:05, 12291.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 252000/311570 [00:19<00:04, 13467.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 248000/311570 [00:19<00:06, 10056.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 252000/311570 [00:19<00:04, 12080.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 247000/311570 [00:19<00:06, 10256.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 254000/311570 [00:20<00:03, 14893.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 252000/311570 [00:19<00:04, 13448.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 254000/311570 [00:20<00:04, 13056.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 246000/311570 [00:20<00:06, 9785.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 249000/311570 [00:20<00:05, 11243.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 251000/311570 [00:20<00:05, 11676.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 256000/311570 [00:20<00:03, 14814.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 254000/311570 [00:20<00:04, 13356.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 256000/311570 [00:20<00:04, 13830.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 251000/311570 [00:20<00:05, 11804.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 253000/311570 [00:20<00:04, 12523.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 249000/311570 [00:20<00:05, 11339.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 247000/311570 [00:20<00:07, 8839.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 258000/311570 [00:20<00:03, 15480.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 256000/311570 [00:20<00:03, 13924.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 247000/311570 [00:20<00:07, 8609.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 258000/311570 [00:20<00:04, 12705.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 253000/311570 [00:20<00:04, 12689.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 249000/311570 [00:20<00:06, 9741.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 251000/311570 [00:20<00:05, 11584.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|███████▉  | 249000/311570 [00:20<00:06, 9943.21 examples/s]#015Running tokenizer on dataset:  83%|████████▎ | 258000/311570 [00:20<00:03, 14369.90 examples/s]#015Running tokenizer on dataset:  83%|████████▎ | 260000/311570 [00:20<00:03, 14478.51 examples/s]#015Running tokenizer on dataset:  82%|████████▏ | 256000/311570 [00:20<00:04, 13626.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 260000/311570 [00:20<00:03, 13339.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 255000/311570 [00:20<00:04, 13486.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 253000/311570 [00:20<00:04, 12149.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 251000/311570 [00:20<00:05, 10906.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 251000/311570 [00:20<00:05, 10686.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 260000/311570 [00:20<00:03, 14185.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 258000/311570 [00:20<00:04, 13277.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 262000/311570 [00:20<00:03, 13487.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 257000/311570 [00:20<00:04, 13596.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 262000/311570 [00:20<00:03, 14504.56 examples/s]#015Running tokenizer on dataset:  81%|████████  | 253000/311570 [00:20<00:05, 11647.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 253000/311570 [00:20<00:04, 11714.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 260000/311570 [00:20<00:03, 14080.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 255000/311570 [00:20<00:04, 12351.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▍ | 264000/311570 [00:20<00:03, 13988.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 259000/311570 [00:20<00:03, 14123.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 262000/311570 [00:20<00:05, 9153.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 262000/311570 [00:20<00:03, 14496.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 255000/311570 [00:20<00:04, 12418.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 255000/311570 [00:20<00:04, 12474.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 257000/311570 [00:20<00:04, 13085.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▍ | 264000/311570 [00:20<00:03, 13662.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 261000/311570 [00:20<00:03, 13998.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 266000/311570 [00:20<00:03, 13875.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▍ | 264000/311570 [00:20<00:04, 10118.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 257000/311570 [00:20<00:04, 12933.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 266000/311570 [00:20<00:03, 14557.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 257000/311570 [00:20<00:04, 12752.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▍ | 264000/311570 [00:20<00:03, 14046.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 259000/311570 [00:20<00:03, 13219.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 268000/311570 [00:21<00:03, 13807.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 263000/311570 [00:21<00:03, 12674.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 268000/311570 [00:21<00:03, 14263.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 259000/311570 [00:21<00:04, 12997.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 266000/311570 [00:21<00:04, 10906.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 261000/311570 [00:21<00:03, 13644.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 259000/311570 [00:21<00:04, 13004.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 266000/311570 [00:21<00:03, 13896.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 270000/311570 [00:21<00:02, 13930.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 265000/311570 [00:21<00:03, 13241.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 261000/311570 [00:21<00:03, 13546.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 263000/311570 [00:21<00:03, 13745.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 270000/311570 [00:21<00:02, 14038.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 268000/311570 [00:21<00:03, 13599.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 261000/311570 [00:21<00:03, 12836.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 268000/311570 [00:21<00:03, 11268.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 272000/311570 [00:21<00:02, 13437.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 267000/311570 [00:21<00:03, 14075.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 265000/311570 [00:21<00:03, 13963.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 263000/311570 [00:21<00:03, 13369.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 270000/311570 [00:21<00:02, 13986.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 272000/311570 [00:21<00:02, 13847.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 270000/311570 [00:21<00:03, 12075.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 263000/311570 [00:21<00:03, 12832.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▋ | 269000/311570 [00:21<00:03, 13411.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 267000/311570 [00:21<00:03, 13988.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 272000/311570 [00:21<00:02, 14284.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 265000/311570 [00:21<00:03, 13621.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 265000/311570 [00:21<00:03, 13192.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 273000/311570 [00:21<00:02, 13373.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 271000/311570 [00:21<00:02, 14188.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 274000/311570 [00:21<00:03, 9815.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▋ | 269000/311570 [00:21<00:03, 14150.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 267000/311570 [00:21<00:03, 13997.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 268000/311570 [00:21<00:02, 14925.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 275000/311570 [00:21<00:02, 13785.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▊ | 276000/311570 [00:21<00:03, 11132.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▋ | 269000/311570 [00:21<00:02, 14536.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 271000/311570 [00:21<00:02, 14556.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 270000/311570 [00:21<00:02, 15159.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 275000/311570 [00:21<00:03, 9431.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 274000/311570 [00:21<00:03, 9802.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 277000/311570 [00:21<00:02, 12920.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 278000/311570 [00:21<00:02, 11357.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 271000/311570 [00:21<00:02, 13682.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 272000/311570 [00:21<00:02, 15315.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 277000/311570 [00:21<00:03, 10464.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▊ | 276000/311570 [00:21<00:03, 11004.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 279000/311570 [00:22<00:02, 13837.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 273000/311570 [00:22<00:04, 8586.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 280000/311570 [00:22<00:02, 12260.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 279000/311570 [00:22<00:02, 11410.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 278000/311570 [00:22<00:02, 11901.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 281000/311570 [00:22<00:02, 14349.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 275000/311570 [00:22<00:03, 10138.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 282000/311570 [00:22<00:02, 13190.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 273000/311570 [00:22<00:04, 8367.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 280000/311570 [00:22<00:02, 12726.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 283000/311570 [00:22<00:01, 14398.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 281000/311570 [00:22<00:02, 11710.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 274000/311570 [00:22<00:03, 10256.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 284000/311570 [00:22<00:02, 13310.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 278000/311570 [00:22<00:02, 11847.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 273000/311570 [00:22<00:04, 8825.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 275000/311570 [00:22<00:03, 9438.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 282000/311570 [00:22<00:02, 13024.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 283000/311570 [00:22<00:02, 12438.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▊ | 276000/311570 [00:22<00:03, 11759.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████▏| 285000/311570 [00:22<00:01, 13898.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 275000/311570 [00:22<00:03, 9952.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 280000/311570 [00:22<00:02, 12094.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 286000/311570 [00:22<00:01, 12909.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 284000/311570 [00:22<00:02, 13392.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 277000/311570 [00:22<00:03, 10165.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 287000/311570 [00:22<00:01, 13774.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████▏| 285000/311570 [00:22<00:02, 12445.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 278000/311570 [00:22<00:02, 12010.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 288000/311570 [00:22<00:01, 13011.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 277000/311570 [00:22<00:03, 10519.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 282000/311570 [00:22<00:02, 12193.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 286000/311570 [00:22<00:01, 13959.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 280000/311570 [00:22<00:02, 12486.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 287000/311570 [00:22<00:01, 12528.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 280000/311570 [00:22<00:02, 11954.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|████████▉ | 279000/311570 [00:22<00:02, 11436.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 288000/311570 [00:22<00:01, 14398.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 290000/311570 [00:22<00:01, 13191.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 284000/311570 [00:22<00:02, 12128.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 282000/311570 [00:22<00:02, 12902.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 289000/311570 [00:22<00:01, 13301.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 282000/311570 [00:22<00:02, 12543.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▎| 292000/311570 [00:22<00:01, 13670.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 281000/311570 [00:22<00:02, 12048.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 286000/311570 [00:22<00:01, 13390.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 290000/311570 [00:22<00:01, 14348.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 284000/311570 [00:23<00:02, 12936.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 284000/311570 [00:23<00:02, 13155.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 291000/311570 [00:23<00:01, 13235.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 283000/311570 [00:23<00:02, 12597.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▎| 292000/311570 [00:23<00:01, 14147.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 290000/311570 [00:23<00:02, 8950.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 288000/311570 [00:23<00:01, 13343.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 294000/311570 [00:23<00:01, 13330.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 286000/311570 [00:23<00:01, 13299.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 286000/311570 [00:23<00:01, 13096.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 293000/311570 [00:23<00:01, 12827.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 290000/311570 [00:23<00:01, 13787.39 examples/s]#015Running tokenizer on dataset:  91%|█████████▏| 285000/311570 [00:23<00:02, 12932.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▎| 292000/311570 [00:23<00:01, 9861.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 294000/311570 [00:23<00:01, 13847.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 296000/311570 [00:23<00:01, 13446.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 288000/311570 [00:23<00:01, 13573.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▍| 295000/311570 [00:23<00:01, 13776.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 288000/311570 [00:23<00:01, 13022.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 287000/311570 [00:23<00:01, 12985.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▎| 292000/311570 [00:23<00:01, 13393.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 294000/311570 [00:23<00:01, 10655.85 examples/s]#015Running tokenizer on dataset:  96%|█████████▌| 298000/311570 [00:23<00:01, 13501.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 296000/311570 [00:23<00:01, 13015.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 290000/311570 [00:23<00:01, 13518.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 297000/311570 [00:23<00:01, 13663.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 290000/311570 [00:23<00:01, 13242.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 289000/311570 [00:23<00:01, 12925.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 296000/311570 [00:23<00:01, 11221.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 298000/311570 [00:23<00:00, 13735.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 299000/311570 [00:23<00:00, 13764.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▎| 292000/311570 [00:23<00:01, 13386.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▎| 292000/311570 [00:23<00:01, 13403.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▍| 295000/311570 [00:23<00:01, 13394.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 291000/311570 [00:23<00:01, 13445.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 298000/311570 [00:23<00:01, 12085.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▋| 300000/311570 [00:23<00:01, 9754.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 297000/311570 [00:23<00:01, 14081.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 294000/311570 [00:23<00:01, 13949.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▋| 300000/311570 [00:23<00:00, 13221.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▍| 295000/311570 [00:23<00:01, 13948.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 293000/311570 [00:23<00:01, 13001.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 299000/311570 [00:23<00:00, 14352.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 296000/311570 [00:23<00:01, 13939.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 302000/311570 [00:23<00:00, 10429.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▋| 300000/311570 [00:23<00:01, 9659.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 302000/311570 [00:23<00:00, 14038.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 297000/311570 [00:23<00:01, 13981.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▍| 295000/311570 [00:23<00:01, 13948.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 304000/311570 [00:24<00:00, 14965.00 examples/s]#015Running tokenizer on dataset:  98%|█████████▊| 304000/311570 [00:24<00:00, 11335.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 302000/311570 [00:24<00:00, 10731.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 298000/311570 [00:24<00:00, 13722.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 302000/311570 [00:24<00:01, 9074.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 299000/311570 [00:24<00:00, 13738.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 306000/311570 [00:24<00:00, 15064.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 304000/311570 [00:24<00:00, 11590.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 306000/311570 [00:24<00:00, 11976.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 298000/311570 [00:24<00:01, 13443.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 304000/311570 [00:24<00:00, 9837.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 308000/311570 [00:24<00:00, 13504.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 301000/311570 [00:24<00:01, 8810.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 306000/311570 [00:24<00:00, 12070.16 examples/s]#015Running tokenizer on dataset:  99%|█████████▉| 309000/311570 [00:24<00:00, 16202.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 306000/311570 [00:24<00:00, 11122.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 310000/311570 [00:24<00:00, 14748.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 308000/311570 [00:24<00:00, 13033.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|█████████▉| 311000/311570 [00:24<00:00, 16123.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 303000/311570 [00:24<00:00, 9949.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▋| 300000/311570 [00:24<00:01, 8474.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 301000/311570 [00:24<00:01, 9473.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 308000/311570 [00:24<00:00, 11714.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 303000/311570 [00:24<00:00, 10990.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 305000/311570 [00:24<00:00, 10879.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 302000/311570 [00:24<00:00, 10008.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|█████████▉| 311000/311570 [00:24<00:00, 14326.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▋| 300000/311570 [00:24<00:01, 8689.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 310000/311570 [00:24<00:00, 12695.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 304000/311570 [00:24<00:00, 11525.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 305000/311570 [00:24<00:00, 12209.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▊| 307000/311570 [00:24<00:00, 12004.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<01:15, 4099.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 311570/311570 [00:24<00:00, 12899.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]#015Grouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<01:21, 3832.34 examples/s]#015Running tokenizer on dataset:  97%|█████████▋| 303000/311570 [00:24<00:00, 10979.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▊| 307000/311570 [00:24<00:00, 13337.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 309000/311570 [00:24<00:00, 12886.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▊| 307000/311570 [00:24<00:00, 13972.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 305000/311570 [00:24<00:00, 12232.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<01:14, 4156.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|█████████▉| 311000/311570 [00:25<00:00, 14003.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 309000/311570 [00:24<00:00, 14755.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<01:13, 4237.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|█████████▉| 311000/311570 [00:25<00:00, 16112.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▊| 307000/311570 [00:24<00:00, 13282.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<01:17, 3997.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<01:20, 3866.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 311570/311570 [00:25<00:00, 16266.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<01:07, 4600.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|█████████▉| 311000/311570 [00:25<00:00, 17236.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<01:05, 4725.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/311570 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<01:00, 5152.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<01:08, 4518.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<01:05, 4722.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<00:58, 5281.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<00:57, 5417.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<01:00, 5109.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 1000/311570 [00:00<00:51, 6020.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<01:00, 5092.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<00:52, 5879.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<00:58, 5255.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<01:02, 4937.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<00:52, 5905.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<00:51, 5986.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<00:57, 5359.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 2000/311570 [00:00<00:49, 6290.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:55, 5526.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<00:51, 6019.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:01<00:56, 5404.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<00:56, 5428.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<00:51, 6001.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<00:51, 6041.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:53, 5739.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|          | 3000/311570 [00:00<00:49, 6222.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:55, 5554.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<00:51, 5945.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:53, 5753.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:55, 5458.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<00:52, 5897.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<00:51, 5918.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:53, 5693.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:50, 5996.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:49, 6163.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   1%|▏         | 4000/311570 [00:00<00:51, 6028.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:51, 5918.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:50, 6091.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:53, 5664.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:50, 6111.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:49, 6116.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:48, 6203.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 5000/311570 [00:00<00:49, 6181.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:51, 5965.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:49, 6118.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:50, 6053.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:51, 5897.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:48, 6293.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:01<00:51, 5903.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:48, 6236.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:48, 6322.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 6000/311570 [00:00<00:51, 5952.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:49, 6169.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:48, 6210.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:48, 6230.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:47, 6309.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:48, 6253.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:47, 6337.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:47, 6445.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   2%|▏         | 7000/311570 [00:01<00:48, 6287.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:48, 6270.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:48, 6211.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:47, 6337.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:47, 6393.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:47, 6359.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:47, 6369.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:47, 6405.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 8000/311570 [00:01<00:47, 6390.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:47, 6319.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:47, 6289.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:48, 6300.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:46, 6431.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:47, 6326.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:02<00:47, 6336.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:46, 6469.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 9000/311570 [00:01<00:47, 6355.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:02<00:47, 6289.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:47, 6320.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:47, 6363.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:02<00:46, 6382.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:47, 6386.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6313.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:46, 6491.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   3%|▎         | 10000/311570 [00:01<00:46, 6417.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6275.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:02<00:47, 6271.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:47, 6366.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6350.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:46, 6401.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:01<00:46, 6433.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:48, 6163.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▎         | 11000/311570 [00:01<00:46, 6426.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:48, 6131.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6239.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:01<00:47, 6309.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:47, 6203.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:01<00:47, 6342.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:46, 6399.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:48, 6169.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 12000/311570 [00:01<00:47, 6366.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:48, 6139.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6277.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:48, 6091.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:47, 6203.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6302.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6212.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:47, 6245.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 13000/311570 [00:02<00:47, 6326.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6175.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:48, 6082.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:48, 6126.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6246.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:48, 6144.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6331.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:47, 6230.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   4%|▍         | 14000/311570 [00:02<00:48, 6168.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6293.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:48, 6127.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:48, 6124.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6355.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:48, 6143.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:03<00:44, 6568.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6274.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▍         | 15000/311570 [00:02<00:48, 6163.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:03<00:44, 6534.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:02<00:44, 6602.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:47, 6245.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6168.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6186.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:44, 6628.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6392.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:44, 6601.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 16000/311570 [00:02<00:47, 6206.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:02<00:45, 6481.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:43, 6662.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6281.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6303.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:45, 6465.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:02<00:44, 6639.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   5%|▌         | 17000/311570 [00:02<00:46, 6326.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:45, 6432.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:44, 6540.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:44, 6487.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:02<00:45, 6511.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:02<00:44, 6541.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:02<00:43, 6703.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:47, 6178.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 18000/311570 [00:02<00:44, 6566.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:47, 6141.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:45, 6371.10 examples/s]#015Grouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:44, 6568.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:46, 6199.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:44, 6596.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:44, 6527.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▌         | 19000/311570 [00:03<00:44, 6625.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:47, 6084.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:47, 6033.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:45, 6396.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:47, 6073.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:45, 6422.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:47, 6102.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:46, 6237.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6243.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   6%|▋         | 20000/311570 [00:03<00:45, 6445.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6201.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6266.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:47, 6115.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:48, 5977.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:47, 6132.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:47, 6127.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:46, 6206.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 21000/311570 [00:03<00:47, 6161.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:04<00:46, 6179.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:46, 6233.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6145.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:48, 6020.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:47, 6037.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:45, 6287.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:04<00:46, 6221.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 22000/311570 [00:03<00:47, 6061.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:04<00:46, 6197.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:04<00:45, 6252.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6181.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:47, 6116.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6203.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:44, 6427.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:45, 6252.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   7%|▋         | 23000/311570 [00:03<00:46, 6223.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:44, 6393.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:44, 6458.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:46, 6153.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:04<00:46, 6138.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:46, 6172.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:03<00:45, 6265.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:45, 6211.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 24000/311570 [00:03<00:46, 6188.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:46, 6183.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:45, 6338.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:45, 6240.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:04<00:46, 6158.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:04<00:46, 6193.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:44, 6472.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 25000/311570 [00:03<00:46, 6203.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:46, 6109.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:45, 6342.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:46, 6159.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:46, 6122.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:44, 6393.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:45, 6263.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   8%|▊         | 26000/311570 [00:04<00:44, 6410.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<01:01, 4634.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:44, 6364.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:44, 6415.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:46, 6139.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:46, 6051.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:46, 6174.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:45, 6189.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:54, 5159.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▊         | 27000/311570 [00:04<00:45, 6188.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:42, 6643.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:42, 6702.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:44, 6306.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:46, 6078.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:43, 6453.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:46, 6102.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:05<00:49, 5675.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:05<00:41, 6778.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:04<00:40, 6849.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 28000/311570 [00:04<00:46, 6122.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:42, 6583.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:44, 6331.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:41, 6736.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:44, 6357.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:05<00:46, 6041.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:39, 6997.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:39, 7081.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   9%|▉         | 29000/311570 [00:04<00:44, 6382.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:05<00:41, 6726.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:42, 6606.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:04<00:40, 6877.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:42, 6639.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:43, 6432.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:40, 6824.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 30000/311570 [00:04<00:42, 6665.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:40, 6905.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:40, 6951.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:04<00:39, 7108.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:04<00:41, 6739.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:04<00:41, 6769.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:43, 6441.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:39, 6964.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|▉         | 31000/311570 [00:04<00:41, 6810.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:39, 7061.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:41, 6777.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:40, 6952.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:39, 6992.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:40, 6926.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:41, 6687.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  10%|█         | 32000/311570 [00:05<00:39, 7039.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:42, 6511.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:41, 6624.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:40, 6920.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:39, 7080.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:41, 6783.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:40, 6811.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:43, 6370.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 33000/311570 [00:05<00:40, 6860.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6282.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6375.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:40, 6928.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:39, 6963.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:42, 6493.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:41, 6639.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 34000/311570 [00:05<00:39, 7012.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:44, 6189.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:06<00:43, 6328.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:05<00:42, 6405.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:42, 6511.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:42, 6541.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6267.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6398.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  11%|█         | 35000/311570 [00:05<00:42, 6578.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:06<00:43, 6257.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:06<00:41, 6532.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:06<00:41, 6608.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:05<00:43, 6295.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6282.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:05<00:42, 6431.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6311.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:06<00:42, 6481.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 36000/311570 [00:05<00:43, 6341.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6722.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6793.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:06<00:42, 6491.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:05<00:41, 6631.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:05<00:43, 6312.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:05<00:43, 6343.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6678.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 37000/311570 [00:05<00:43, 6372.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:40, 6629.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:40, 6704.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6666.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6813.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:06<00:42, 6508.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:05<00:41, 6540.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:41, 6609.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  12%|█▏        | 38000/311570 [00:05<00:41, 6565.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:39, 6790.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:39, 6871.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:40, 6728.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:41, 6584.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6686.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6715.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:39, 6779.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 39000/311570 [00:06<00:40, 6744.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:39, 6903.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:38, 6989.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:39, 6900.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:40, 6738.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:41, 6597.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:41, 6621.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:39, 6901.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 40000/311570 [00:06<00:40, 6654.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:40, 6635.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:40, 6706.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:38, 7024.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:39, 6847.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:40, 6754.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:39, 6786.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:07<00:40, 6626.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 41000/311570 [00:06<00:39, 6810.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:07<00:40, 6581.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:06<00:40, 6647.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:39, 6745.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:39, 6870.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:39, 6908.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:40, 6576.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  13%|█▎        | 42000/311570 [00:06<00:38, 6930.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:07<00:40, 6571.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:40, 6508.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:41, 6447.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:06<00:40, 6675.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:40, 6599.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:07<00:41, 6515.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:40, 6622.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:41, 6438.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 43000/311570 [00:06<00:40, 6654.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:39, 6676.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:40, 6614.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:06<00:40, 6542.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:06<00:40, 6539.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:06<00:40, 6556.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:41, 6380.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:40, 6606.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 44000/311570 [00:06<00:40, 6593.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6562.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6497.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:39, 6713.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:40, 6544.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:41, 6405.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:41, 6420.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6497.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  14%|█▍        | 45000/311570 [00:07<00:41, 6456.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6737.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6659.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6591.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:40, 6573.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:40, 6592.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:41, 6428.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6653.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 7091.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 7001.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▍        | 46000/311570 [00:07<00:40, 6625.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6752.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:40, 6583.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 7012.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6464.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6478.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:37, 6964.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:38, 6864.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 47000/311570 [00:07<00:40, 6510.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:36, 7102.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 6930.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6621.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6636.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:08<00:38, 6875.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:07<00:37, 6957.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:08<00:38, 6856.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  15%|█▌        | 48000/311570 [00:07<00:39, 6661.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:37, 6969.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 6966.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:38, 6806.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 6993.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:08<00:37, 6870.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 49000/311570 [00:07<00:37, 7017.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:37, 6838.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:38, 6735.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:07<00:37, 6960.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:08<00:38, 6798.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:38, 6831.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:38, 6868.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:38, 6742.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▌        | 50000/311570 [00:07<00:37, 6890.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:38, 6761.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:38, 6671.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:07<00:37, 6831.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:07<00:38, 6817.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:07<00:38, 6849.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:38, 6675.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:38, 6664.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  16%|█▋        | 51000/311570 [00:07<00:37, 6877.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:38, 6709.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:38, 6627.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:38, 6751.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:38, 6690.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:38, 6722.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:39, 6601.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:38, 6621.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 52000/311570 [00:08<00:38, 6752.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6552.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6477.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:38, 6719.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:39, 6619.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:38, 6651.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:39, 6558.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6470.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 53000/311570 [00:08<00:38, 6673.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:40, 6269.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:41, 6202.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6563.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:39, 6583.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:38, 6616.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6421.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  17%|█▋        | 54000/311570 [00:08<00:38, 6643.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:09<00:41, 6196.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:08<00:40, 6255.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:09<00:41, 6201.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:40, 6279.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6439.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6472.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:41, 6155.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 55000/311570 [00:08<00:39, 6492.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:09<00:41, 6188.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:09<00:39, 6341.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:09<00:40, 6287.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:08<00:40, 6278.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:41, 6169.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:41, 6193.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:09<00:41, 6154.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 56000/311570 [00:08<00:41, 6212.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:09<00:40, 6266.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6426.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6369.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:08<00:39, 6364.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:08<00:41, 6168.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:08<00:41, 6187.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:09<00:40, 6239.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6348.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  18%|█▊        | 57000/311570 [00:08<00:41, 6206.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6251.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6194.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6443.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:09<00:40, 6246.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:09<00:40, 6266.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6321.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▊        | 58000/311570 [00:08<00:40, 6285.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6186.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:40, 6126.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:41, 6050.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6268.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6349.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6326.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6151.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 59000/311570 [00:09<00:39, 6363.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:41, 6051.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 6052.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 5983.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:40, 6123.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6171.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6158.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:41, 6014.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  19%|█▉        | 60000/311570 [00:09<00:40, 6189.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:10<00:41, 5985.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:09<00:41, 5999.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:10<00:41, 5953.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 6052.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:41, 6040.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:41, 6026.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 5948.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 61000/311570 [00:09<00:41, 6056.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:10<00:39, 6257.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:10<00:41, 5943.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:10<00:39, 6203.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:09<00:41, 6014.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 5975.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 5963.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:10<00:42, 5907.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|█▉        | 62000/311570 [00:09<00:41, 5991.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:38, 6425.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:10<00:39, 6191.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:38, 6367.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:09<00:39, 6264.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:09<00:41, 5935.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:09<00:42, 5915.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:10<00:40, 6154.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:38, 6335.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:38, 6308.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  20%|██        | 63000/311570 [00:09<00:41, 5949.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:39, 6258.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:38, 6433.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:10<00:40, 6183.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:10<00:40, 6153.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:39, 6310.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 64000/311570 [00:09<00:39, 6199.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:39, 6235.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:38, 6355.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:38, 6305.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:38, 6326.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:38, 6346.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:39, 6310.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:39, 6202.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 65000/311570 [00:10<00:38, 6360.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:38, 6286.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:38, 6271.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:38, 6382.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:39, 6209.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:39, 6238.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:39, 6207.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:39, 6244.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  21%|██        | 66000/311570 [00:10<00:39, 6260.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:37, 6452.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:39, 6199.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:37, 6396.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:38, 6300.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:38, 6285.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:39, 6258.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:39, 6162.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:10<00:37, 6495.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 67000/311570 [00:10<00:38, 6309.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:11<00:37, 6387.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:11<00:37, 6435.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:37, 6487.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:39, 6203.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:39, 6174.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:38, 6356.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:36, 6559.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:11<00:37, 6422.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 68000/311570 [00:10<00:39, 6220.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:37, 6494.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:10<00:37, 6525.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:37, 6389.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:38, 6363.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:11<00:37, 6403.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:37, 6486.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 69000/311570 [00:10<00:37, 6411.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:37, 6344.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:10<00:36, 6592.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:38, 6277.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:10<00:37, 6428.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:11<00:37, 6404.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:37, 6464.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  22%|██▏       | 70000/311570 [00:10<00:37, 6450.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:37, 6310.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:38, 6278.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:37, 6366.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:38, 6244.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:37, 6484.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:37, 6460.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 71000/311570 [00:11<00:36, 6510.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:38, 6250.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:36, 6440.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:38, 6243.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:37, 6333.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:37, 6366.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:38, 6272.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:38, 6251.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:38, 6202.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 72000/311570 [00:11<00:38, 6298.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:37, 6375.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:37, 6271.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:36, 6463.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:38, 6206.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:38, 6233.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:38, 6219.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:37, 6333.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  23%|██▎       | 73000/311570 [00:11<00:38, 6263.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:11<00:37, 6249.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:12<00:38, 6210.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:37, 6293.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:12<00:38, 6197.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:37, 6367.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:37, 6348.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 74000/311570 [00:11<00:37, 6388.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:36, 6422.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:38, 6171.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:12<00:38, 6194.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:11<00:37, 6280.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:36, 6371.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:38, 6205.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:38, 6186.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6461.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 75000/311570 [00:11<00:38, 6218.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:12<00:38, 6158.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:36, 6370.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:11<00:36, 6456.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6409.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:11<00:38, 6194.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:35, 6468.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:11<00:38, 6170.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:37, 6338.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6402.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  24%|██▍       | 76000/311570 [00:11<00:37, 6207.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:35, 6495.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:36, 6418.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:36, 6371.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:37, 6334.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6404.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6367.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▍       | 77000/311570 [00:12<00:36, 6382.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:36, 6403.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:35, 6490.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6355.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6404.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6366.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:36, 6363.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 78000/311570 [00:12<00:36, 6424.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:36, 6251.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6338.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:35, 6435.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:37, 6204.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:36, 6393.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:36, 6367.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  25%|██▌       | 79000/311570 [00:12<00:36, 6411.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6294.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:12<00:37, 6182.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:13<00:37, 6195.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:36, 6284.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:13<00:37, 6132.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6333.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6303.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 80000/311570 [00:12<00:36, 6347.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:13<00:36, 6219.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:37, 6160.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:13<00:37, 6112.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:12<00:36, 6217.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:13<00:37, 6167.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:37, 6191.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:37, 6169.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:35, 6335.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▌       | 81000/311570 [00:12<00:37, 6205.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:13<00:37, 6090.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:13<00:37, 6153.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:12<00:36, 6256.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:36, 6284.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:12<00:37, 6120.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:35, 6391.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:12<00:37, 6099.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  26%|██▋       | 82000/311570 [00:12<00:37, 6134.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:13<00:37, 6127.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:36, 6269.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:35, 6373.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:35, 6331.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:34, 6533.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:13<00:37, 6154.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:13<00:37, 6126.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:36, 6244.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 83000/311570 [00:12<00:37, 6172.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:35, 6318.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:35, 6420.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:34, 6465.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6540.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:36, 6266.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:36, 6239.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:34, 6460.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:34, 6561.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 84000/311570 [00:13<00:36, 6285.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:36, 6293.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6460.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:35, 6319.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:13<00:35, 6329.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:36, 6291.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6560.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:35, 6421.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6474.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  27%|██▋       | 85000/311570 [00:13<00:35, 6338.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:13<00:35, 6255.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:35, 6439.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:35, 6432.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 86000/311570 [00:13<00:34, 6481.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:13<00:35, 6227.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6426.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:13<00:35, 6345.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:14<00:35, 6261.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:14<00:36, 6154.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6450.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6446.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 87000/311570 [00:13<00:34, 6479.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6301.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:14<00:35, 6223.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:13<00:35, 6238.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:14<00:36, 6157.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6227.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:13<00:35, 6252.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:13<00:35, 6243.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  28%|██▊       | 88000/311570 [00:13<00:35, 6272.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 6096.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:13<00:35, 6303.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:14<00:36, 6123.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6223.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 6015.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:13<00:36, 6158.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:34, 6292.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:14<00:36, 6146.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▊       | 89000/311570 [00:13<00:36, 6174.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6193.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 6089.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 6013.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:35, 6208.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6222.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6365.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6209.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 90000/311570 [00:14<00:35, 6239.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:34, 6288.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:35, 6207.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 5979.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6289.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:33, 6435.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 6010.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6364.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 5997.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  29%|██▉       | 91000/311570 [00:14<00:36, 6025.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6283.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:35, 6156.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:34, 6357.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:14<00:33, 6404.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:35, 6202.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:33, 6439.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:35, 6188.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 92000/311570 [00:14<00:35, 6218.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:15<00:34, 6346.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:35, 6228.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:15<00:34, 6324.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:34, 6269.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6287.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:14<00:33, 6408.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6266.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|██▉       | 93000/311570 [00:14<00:34, 6297.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:15<00:34, 6317.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:34, 6304.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:34, 6198.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:34, 6363.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6234.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:34, 6335.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 94000/311570 [00:14<00:34, 6373.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:14<00:34, 6284.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:15<00:34, 6273.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:34, 6199.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6174.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:14<00:34, 6328.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:14<00:34, 6341.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  30%|███       | 95000/311570 [00:15<00:34, 6303.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 6039.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6255.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6171.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:35, 6155.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 5987.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:34, 6202.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:34, 6215.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 6066.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 96000/311570 [00:15<00:34, 6175.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 6063.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:35, 6126.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 5982.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 6008.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6353.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6167.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6179.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███       | 97000/311570 [00:15<00:34, 6147.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:34, 6076.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 6008.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:36, 5930.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6280.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:15<00:32, 6570.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6370.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 5967.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 5992.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  31%|███▏      | 98000/311570 [00:15<00:35, 5962.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:16<00:33, 6286.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:16<00:32, 6488.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 5955.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:32, 6386.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:15<00:31, 6594.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 5989.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:16<00:32, 6494.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 6002.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 99000/311570 [00:15<00:35, 5982.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6236.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:33, 6318.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6685.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:15<00:32, 6415.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6271.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6288.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 100000/311570 [00:15<00:33, 6260.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:33, 6324.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:16<00:32, 6444.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6617.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6694.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:15<00:31, 6718.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:15<00:32, 6490.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:15<00:32, 6508.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6620.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  32%|███▏      | 101000/311570 [00:15<00:32, 6474.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6628.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:33, 6279.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6564.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:30, 6723.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:33, 6323.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6632.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:33, 6338.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 102000/311570 [00:16<00:33, 6297.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6575.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6503.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6376.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6592.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6621.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6635.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 103000/311570 [00:16<00:31, 6588.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6499.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6579.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6307.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:16<00:31, 6491.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6634.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6400.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6645.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  33%|███▎      | 104000/311570 [00:16<00:31, 6603.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6310.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:32, 6441.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:17<00:31, 6425.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:16<00:31, 6425.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:16<00:31, 6523.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6498.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6515.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▎      | 105000/311570 [00:16<00:31, 6474.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:17<00:31, 6423.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6253.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:17<00:31, 6365.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6515.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:16<00:31, 6459.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6310.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6316.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 106000/311570 [00:16<00:32, 6282.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:17<00:31, 6364.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:17<00:32, 6363.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6450.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6471.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:16<00:30, 6550.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:16<00:31, 6425.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:16<00:31, 6437.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  34%|███▍      | 107000/311570 [00:16<00:31, 6396.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6453.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:17<00:32, 6308.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6410.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:30, 6553.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6497.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:17<00:31, 6363.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:16<00:31, 6382.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 108000/311570 [00:17<00:32, 6345.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6409.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6406.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:30, 6492.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:29, 6663.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:30, 6581.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6453.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6475.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:30, 6488.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▍      | 109000/311570 [00:17<00:31, 6419.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:30, 6602.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6361.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:29, 6651.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:29, 6693.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6406.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6428.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:30, 6594.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  35%|███▌      | 110000/311570 [00:17<00:31, 6375.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:30, 6578.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:31, 6435.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:17<00:29, 6759.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:29, 6673.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:30, 6484.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:30, 6507.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:18<00:30, 6579.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 111000/311570 [00:17<00:31, 6447.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:18<00:29, 6684.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:30, 6550.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:17<00:29, 6689.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:17<00:29, 6782.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:30, 6598.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:30, 6618.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:18<00:29, 6673.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▌      | 112000/311570 [00:17<00:30, 6553.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:18<00:29, 6628.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:30, 6534.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:29, 6577.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:17<00:29, 6717.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:30, 6588.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:30, 6602.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:18<00:29, 6612.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  36%|███▋      | 113000/311570 [00:17<00:30, 6541.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:18<00:29, 6641.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:30, 6504.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:28, 6750.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:17<00:29, 6589.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:17<00:29, 6690.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:17<00:29, 6708.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 114000/311570 [00:17<00:29, 6640.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:30, 6486.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:29, 6677.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:18<00:29, 6581.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:27, 6930.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:28, 6767.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:18<00:29, 6631.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:17<00:29, 6646.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:29, 6662.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 115000/311570 [00:18<00:29, 6580.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:28, 6844.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:30, 6461.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:28, 6698.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:27, 6947.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:28, 6841.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:30, 6500.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:29, 6520.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  37%|███▋      | 116000/311570 [00:18<00:30, 6461.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:29, 6618.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:29, 6623.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:18<00:27, 6908.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:28, 6721.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:29, 6668.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:29, 6691.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:29, 6627.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:18<00:28, 6824.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 117000/311570 [00:18<00:29, 6626.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:28, 6784.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:18<00:27, 6930.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:18<00:29, 6531.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:28, 6839.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:28, 6868.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:19<00:28, 6834.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 118000/311570 [00:18<00:28, 6797.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:19<00:29, 6451.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:29, 6562.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:18<00:29, 6554.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6232.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:29, 6616.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:28, 6640.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:19<00:29, 6450.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  38%|███▊      | 119000/311570 [00:18<00:29, 6581.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:19<00:28, 6777.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6166.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:28, 6532.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:18<00:30, 6256.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:18<00:28, 6821.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:18<00:27, 6848.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▊      | 120000/311570 [00:18<00:28, 6789.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6161.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:19<00:29, 6406.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:29, 6460.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6628.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:28, 6555.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:18<00:29, 6447.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:18<00:29, 6480.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:29, 6458.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 121000/311570 [00:19<00:29, 6423.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6559.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:27, 6676.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6127.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6656.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6158.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6559.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6184.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:28, 6603.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 122000/311570 [00:19<00:30, 6138.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:29, 6412.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6604.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:27, 6699.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:29, 6450.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:29, 6470.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:28, 6601.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  39%|███▉      | 123000/311570 [00:19<00:29, 6422.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6532.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6494.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:19<00:28, 6569.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6623.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6547.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6566.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:20<00:28, 6527.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|███▉      | 124000/311570 [00:19<00:28, 6515.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:20<00:28, 6497.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:28, 6544.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:19<00:27, 6691.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:19<00:28, 6583.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:28, 6589.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:28, 6606.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:20<00:28, 6493.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 125000/311570 [00:19<00:28, 6559.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:20<00:27, 6626.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6681.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6478.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:19<00:27, 6719.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6519.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6523.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:20<00:27, 6624.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  40%|████      | 126000/311570 [00:19<00:28, 6487.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6614.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:26, 6729.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:20<00:28, 6449.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:19<00:27, 6712.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:19<00:28, 6488.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:19<00:28, 6493.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6609.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:27, 6653.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 127000/311570 [00:19<00:28, 6452.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:26, 6717.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:20<00:27, 6573.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:26, 6751.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:20<00:27, 6620.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:19<00:27, 6630.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:27, 6652.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████      | 128000/311570 [00:20<00:27, 6580.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:27, 6639.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:26, 6743.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:27, 6515.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6559.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6605.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6623.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:27, 6646.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  41%|████▏     | 129000/311570 [00:20<00:27, 6568.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:27, 6453.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:27, 6598.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:20<00:27, 6497.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:27, 6538.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:27, 6645.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:27, 6666.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:27, 6446.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 130000/311570 [00:20<00:27, 6606.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:20<00:27, 6430.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:27, 6578.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:20<00:27, 6422.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:20<00:27, 6520.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:27, 6631.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:27, 6661.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:21<00:27, 6422.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 131000/311570 [00:20<00:27, 6595.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:20<00:26, 6629.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:21<00:27, 6357.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:28, 6386.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:20<00:27, 6439.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:27, 6436.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:27, 6458.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:21<00:27, 6347.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  42%|████▏     | 132000/311570 [00:20<00:28, 6402.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:21<00:26, 6562.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:20<00:26, 6658.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6448.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:21<00:28, 6371.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:20<00:27, 6412.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:20<00:27, 6438.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:21<00:26, 6568.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 133000/311570 [00:20<00:27, 6381.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6401.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6455.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:20<00:27, 6478.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:21<00:28, 6299.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:20<00:27, 6346.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:20<00:27, 6370.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6411.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 134000/311570 [00:21<00:28, 6316.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6406.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:26, 6448.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:21<00:27, 6511.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:26, 6481.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:21<00:26, 6557.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:21<00:26, 6582.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6422.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  43%|████▎     | 135000/311570 [00:21<00:27, 6522.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:27, 6396.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:26, 6477.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6338.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:21<00:28, 6104.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6388.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6411.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:27, 6417.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▎     | 136000/311570 [00:21<00:27, 6351.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6346.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:21<00:28, 6057.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:21<00:28, 6123.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:21<00:28, 6073.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6414.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6382.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 137000/311570 [00:21<00:27, 6362.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:22<00:28, 6079.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:27, 6335.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:22<00:28, 6009.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:21<00:28, 6070.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:21<00:28, 5891.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:27, 6410.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:27, 6379.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  44%|████▍     | 138000/311570 [00:21<00:27, 6350.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:22<00:28, 6025.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6254.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:22<00:28, 5999.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:22<00:29, 5821.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:21<00:28, 5887.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:21<00:28, 6061.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:21<00:28, 6039.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 139000/311570 [00:21<00:28, 6017.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:22<00:29, 5851.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6461.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6177.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:21<00:27, 6244.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:22<00:28, 5952.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:21<00:28, 6008.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:21<00:28, 5994.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6208.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6576.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▍     | 140000/311570 [00:22<00:28, 5975.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6376.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6451.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:22<00:29, 5778.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6407.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:22<00:29, 5822.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:22<00:29, 5812.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:25, 6522.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6565.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6488.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  45%|████▌     | 141000/311570 [00:22<00:29, 5790.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6135.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6175.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6524.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6163.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:22<00:25, 6479.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:25, 6521.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:25, 6449.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 142000/311570 [00:22<00:27, 6138.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6331.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6376.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6359.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:23<00:25, 6483.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:22<00:24, 6607.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:22<00:25, 6477.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 143000/311570 [00:22<00:26, 6343.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:23<00:25, 6397.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:26, 6437.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6482.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6465.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:23<00:25, 6446.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6682.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:22<00:24, 6600.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:23<00:25, 6523.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  46%|████▌     | 144000/311570 [00:22<00:25, 6453.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:26, 6389.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:25, 6438.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:25, 6419.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:23<00:25, 6571.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:24, 6561.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:22<00:24, 6693.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6603.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 145000/311570 [00:22<00:25, 6408.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:23<00:26, 6350.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6655.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:22<00:25, 6399.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:22<00:25, 6383.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6878.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:24, 6580.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:25, 6491.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 146000/311570 [00:22<00:25, 6373.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:23<00:25, 6477.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:22<00:25, 6524.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:23<00:25, 6505.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:24, 6532.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:23, 6770.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6905.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6805.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  47%|████▋     | 147000/311570 [00:23<00:25, 6498.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6558.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6851.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6602.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6587.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:23, 6795.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:23<00:24, 6474.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:23, 6705.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 148000/311570 [00:23<00:24, 6570.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:25, 6446.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:23, 6744.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:25, 6490.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:25, 6473.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:23<00:24, 6494.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:23<00:24, 6399.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:23<00:24, 6404.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 149000/311570 [00:23<00:25, 6453.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6753.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6811.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6781.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:24<00:24, 6446.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:23<00:23, 6644.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 150000/311570 [00:23<00:23, 6763.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:23<00:24, 6416.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:24<00:25, 6333.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:24, 6641.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:23, 6707.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:24, 6676.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6768.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:24<00:24, 6367.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:23<00:23, 6670.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  48%|████▊     | 151000/311570 [00:23<00:24, 6658.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:24<00:23, 6582.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:24<00:25, 6352.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:22, 6851.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:24<00:23, 6609.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:23<00:24, 6400.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:23<00:24, 6388.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:23<00:22, 6807.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6717.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 152000/311570 [00:23<00:25, 6368.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:24<00:25, 6283.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6747.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:22, 6746.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:22, 6890.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:23<00:25, 6323.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:23<00:25, 6314.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:22, 6791.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 153000/311570 [00:24<00:25, 6293.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:24<00:24, 6522.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:22, 6829.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:24<00:23, 6570.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:22, 6778.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:24<00:24, 6561.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6631.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:23, 6683.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  49%|████▉     | 154000/311570 [00:24<00:24, 6529.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6659.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:22, 6723.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6705.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6692.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:24<00:22, 6740.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6663.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6563.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|████▉     | 155000/311570 [00:24<00:23, 6662.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:23, 6736.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:22, 6784.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:22, 6770.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6610.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:24<00:22, 6766.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:24<00:23, 6525.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:25<00:22, 6663.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 156000/311570 [00:24<00:23, 6736.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:23, 6623.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:25<00:22, 6721.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:23, 6680.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:23, 6660.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:24<00:22, 6595.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:24<00:23, 6542.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:25<00:23, 6453.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  50%|█████     | 157000/311570 [00:24<00:23, 6637.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6508.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6561.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:25<00:23, 6499.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6552.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:24<00:22, 6610.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6451.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:25<00:23, 6521.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 158000/311570 [00:24<00:23, 6527.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:25<00:23, 6621.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:24<00:22, 6671.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:25<00:22, 6567.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:24<00:22, 6653.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:24<00:23, 6471.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6283.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████     | 159000/311570 [00:24<00:23, 6624.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6382.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:25<00:23, 6417.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:24<00:23, 6458.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6431.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:25<00:23, 6444.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6307.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 6036.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  51%|█████▏    | 160000/311570 [00:25<00:23, 6416.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6226.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:25<00:23, 6484.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:25<00:23, 6530.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:25<00:23, 6506.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6276.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 6060.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 161000/311570 [00:25<00:23, 6486.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:25<00:24, 5949.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 5985.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6347.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6395.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6372.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 6035.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 162000/311570 [00:25<00:23, 6348.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:25<00:24, 5957.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:25<00:23, 6107.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:26<00:24, 5880.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:24, 6182.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6237.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6202.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:26<00:24, 5937.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:25<00:23, 6111.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:25<00:23, 6196.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  52%|█████▏    | 163000/311570 [00:25<00:23, 6195.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:26<00:24, 6043.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 5947.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 5986.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 5963.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:26<00:23, 6097.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:25<00:23, 6203.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5965.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 164000/311570 [00:25<00:24, 5957.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:26<00:23, 6134.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:26<00:25, 5846.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:26<00:23, 6188.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:25<00:24, 5893.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:25<00:24, 5868.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6185.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:25<00:24, 5979.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 165000/311570 [00:25<00:24, 5864.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5916.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:26<00:24, 6005.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:25<00:24, 6055.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:26<00:24, 6029.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5964.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6194.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6311.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  53%|█████▎    | 166000/311570 [00:26<00:24, 6025.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6132.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:26<00:23, 6098.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:26<00:23, 6150.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6176.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:26<00:23, 6121.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6315.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:26<00:23, 5981.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▎    | 167000/311570 [00:26<00:23, 6111.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6254.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5879.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6296.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5927.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5904.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:26<00:22, 6275.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:26<00:23, 5993.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 168000/311570 [00:26<00:24, 5889.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:26<00:23, 5928.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6083.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6138.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6110.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:27<00:23, 5975.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:26<00:22, 6291.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:26<00:22, 6190.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:27<00:22, 6216.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  54%|█████▍    | 169000/311570 [00:26<00:23, 6103.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6204.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6252.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:27<00:22, 6263.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6231.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:21, 6334.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:26<00:22, 6201.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 170000/311570 [00:26<00:22, 6211.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:27<00:22, 6135.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:27<00:23, 5888.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:27<00:22, 6163.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:26<00:21, 6359.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:26<00:23, 5926.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6383.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:26<00:23, 5908.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:21, 6280.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▍    | 171000/311570 [00:26<00:23, 5892.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:27<00:22, 6173.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:21, 6309.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:26<00:22, 6219.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6414.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:26<00:22, 6197.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6273.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6333.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  55%|█████▌    | 172000/311570 [00:27<00:22, 6177.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:27<00:22, 6094.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6371.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:27<00:22, 6134.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6305.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:27<00:21, 6339.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:27<00:22, 6112.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6232.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 173000/311570 [00:27<00:22, 6093.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:22, 6234.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6262.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:21, 6281.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:27<00:21, 6377.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:27<00:20, 6434.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:21, 6264.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:27<00:21, 6291.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 174000/311570 [00:27<00:22, 6231.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6291.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:28<00:21, 6331.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6334.20 examples/s]#015Grouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:27<00:20, 6462.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:27<00:20, 6381.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6313.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:28<00:20, 6373.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▌    | 175000/311570 [00:27<00:21, 6289.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6178.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:28<00:20, 6421.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:27<00:20, 6413.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6226.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6379.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6208.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:28<00:20, 6329.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  56%|█████▋    | 176000/311570 [00:27<00:21, 6183.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:28<00:21, 6240.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:28<00:20, 6366.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:27<00:20, 6410.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:27<00:21, 6285.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6431.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:27<00:21, 6277.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6329.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 177000/311570 [00:27<00:21, 6251.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:28<00:21, 6324.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6365.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6472.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6575.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:27<00:20, 6384.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:27<00:20, 6368.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6394.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 178000/311570 [00:28<00:21, 6344.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6527.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:28<00:21, 6275.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6426.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6577.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:27<00:20, 6337.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:28<00:20, 6321.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6534.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  57%|█████▋    | 179000/311570 [00:28<00:21, 6291.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6558.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6549.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6278.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:28<00:19, 6486.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6338.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6323.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6532.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 180000/311570 [00:28<00:20, 6288.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6565.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:28<00:19, 6650.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:28<00:19, 6476.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6338.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6397.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6388.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:29<00:19, 6431.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 181000/311570 [00:28<00:20, 6351.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:28<00:18, 6871.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:28<00:19, 6641.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:29<00:19, 6475.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:20, 6459.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6532.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6511.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:29<00:19, 6586.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  58%|█████▊    | 182000/311570 [00:28<00:19, 6484.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:28<00:18, 6870.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6802.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:29<00:19, 6639.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6463.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6531.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6514.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:29<00:18, 6796.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▊    | 183000/311570 [00:28<00:19, 6480.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:29<00:18, 6845.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:28<00:18, 6815.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6401.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:29<00:19, 6383.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:28<00:19, 6444.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:28<00:19, 6425.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6741.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6785.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 184000/311570 [00:28<00:19, 6393.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6659.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6408.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:29<00:19, 6540.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:28<00:19, 6604.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:29<00:19, 6586.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6347.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  59%|█████▉    | 185000/311570 [00:29<00:19, 6530.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6672.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:29<00:18, 6753.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6369.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:29<00:18, 6822.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:29<00:18, 6799.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6592.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|█████▉    | 186000/311570 [00:29<00:18, 6714.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6617.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6679.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:29<00:24, 5020.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6751.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6723.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 187000/311570 [00:29<00:18, 6668.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:29<00:23, 5227.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:29<00:18, 6717.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:29<00:22, 5471.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6273.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:30<00:22, 5407.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6346.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6325.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:29<00:21, 5637.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:30<00:17, 6767.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  60%|██████    | 188000/311570 [00:29<00:19, 6284.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:29<00:20, 5804.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6520.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6598.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:30<00:20, 5767.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6571.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:29<00:20, 5933.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:30<00:17, 6743.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 189000/311570 [00:29<00:18, 6534.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:19, 5930.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:30<00:19, 6006.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:29<00:19, 6031.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:18, 6557.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:29<00:23, 5158.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:30<00:23, 5088.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 6003.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:19, 6066.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:29<00:24, 4986.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 6092.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████    | 190000/311570 [00:30<00:24, 4987.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:18, 6436.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:29<00:21, 5572.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:30<00:21, 5503.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:19, 6121.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 6101.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:30<00:22, 5427.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  61%|██████▏   | 191000/311570 [00:30<00:22, 5420.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:18, 6195.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:18, 6417.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:30<00:20, 5870.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:30<00:20, 5803.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:30<00:18, 6175.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:30<00:20, 5747.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:18, 6180.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 192000/311570 [00:30<00:20, 5731.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:30<00:18, 6235.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:30<00:18, 6377.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:19, 5971.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:30<00:17, 6443.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:20, 5902.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:20, 5875.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:30<00:18, 6203.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:30<00:17, 6479.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 193000/311570 [00:30<00:20, 5858.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:31<00:17, 6581.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:30<00:17, 6515.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 6028.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 5952.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:31<00:17, 6440.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 5949.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:30<00:17, 6547.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:31<00:17, 6603.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  62%|██████▏   | 194000/311570 [00:30<00:19, 5934.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:16, 6639.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:19, 6123.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:19, 6047.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:31<00:17, 6501.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:19, 6063.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:30<00:16, 6670.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:16, 6696.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6688.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 195000/311570 [00:30<00:19, 6047.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:30<00:18, 6165.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:17, 6613.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:31<00:18, 6088.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:30<00:18, 6110.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:30<00:16, 6720.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6718.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6655.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 196000/311570 [00:31<00:18, 6096.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:30<00:17, 6405.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6648.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:31<00:18, 6339.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:31<00:17, 6370.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6688.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6666.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6601.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  63%|██████▎   | 197000/311570 [00:31<00:18, 6345.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:31<00:17, 6476.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6611.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:31<00:17, 6414.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:31<00:17, 6443.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6626.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6588.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▎   | 198000/311570 [00:31<00:17, 6413.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:31<00:16, 6504.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:17, 6594.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:17, 6533.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6545.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:17, 6571.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:31<00:16, 6529.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:31<00:16, 6486.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:31<00:16, 6653.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 199000/311570 [00:31<00:17, 6529.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6643.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6574.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:32<00:16, 6443.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6610.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:31<00:16, 6662.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:31<00:15, 6875.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:32<00:16, 6633.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  64%|██████▍   | 200000/311570 [00:31<00:16, 6574.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6612.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6534.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:32<00:16, 6588.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6574.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:31<00:15, 6886.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:32<00:15, 6851.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 201000/311570 [00:31<00:16, 6548.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6483.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6549.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:32<00:15, 6809.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:32<00:16, 6471.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6507.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:31<00:16, 6505.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6695.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6462.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▍   | 202000/311570 [00:31<00:16, 6489.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:31<00:16, 6454.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:32<00:17, 6380.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6424.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:31<00:16, 6419.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6716.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6793.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6668.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 203000/311570 [00:32<00:16, 6397.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:31<00:16, 6590.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6635.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:32<00:16, 6526.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:32<00:16, 6566.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6814.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6756.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6537.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:32<00:15, 6803.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  65%|██████▌   | 204000/311570 [00:32<00:16, 6542.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:32<00:15, 6752.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6722.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:32<00:15, 6792.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6554.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6497.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 205000/311570 [00:32<00:15, 6752.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:32<00:16, 6338.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6429.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6467.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6379.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6412.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:32<00:15, 6352.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:32<00:15, 6550.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:33<00:16, 6293.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6637.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▌   | 206000/311570 [00:32<00:16, 6382.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6580.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:33<00:16, 6261.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6617.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:32<00:15, 6553.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:33<00:15, 6500.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6731.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  66%|██████▋   | 207000/311570 [00:32<00:15, 6582.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6221.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6665.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:33<00:15, 6463.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6697.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:32<00:15, 6229.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 208000/311570 [00:32<00:15, 6676.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6471.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6177.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:33<00:16, 6409.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5967.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6436.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6148.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5983.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 209000/311570 [00:32<00:15, 6422.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:32<00:16, 6262.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5927.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 6065.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:33<00:16, 6213.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:33<00:16, 6239.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5915.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 6075.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:33<00:15, 6468.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  67%|██████▋   | 210000/311570 [00:33<00:16, 6227.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6347.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 6025.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:33<00:15, 6415.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:33<00:15, 6440.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 6000.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6358.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 211000/311570 [00:33<00:15, 6425.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:33<00:14, 6440.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6303.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6150.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6099.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6279.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6126.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:33<00:14, 6433.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:34<00:14, 6387.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 212000/311570 [00:33<00:16, 6108.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5911.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:33<00:15, 5966.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:34<00:15, 6351.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5861.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5889.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:33<00:15, 5947.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  68%|██████▊   | 213000/311570 [00:33<00:16, 5880.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:34<00:15, 5916.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 6005.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5776.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 5949.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 5972.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:34<00:16, 5886.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6281.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:33<00:16, 5748.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▊   | 214000/311570 [00:33<00:16, 5973.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:34<00:15, 6222.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5719.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5905.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6244.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5692.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:33<00:15, 6348.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 215000/311570 [00:33<00:15, 6244.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5892.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:34<00:15, 6300.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 6034.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5847.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:33<00:15, 6322.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5829.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  69%|██████▉   | 216000/311570 [00:34<00:15, 6316.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 6015.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6261.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:34<00:16, 5879.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 5971.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:34<00:16, 5836.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:34<00:16, 5857.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 5956.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6245.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:34<00:14, 6383.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 217000/311570 [00:34<00:16, 5859.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6194.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5688.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6171.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5649.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5668.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:34<00:14, 6358.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:34<00:13, 6578.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:35<00:14, 6307.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|██████▉   | 218000/311570 [00:34<00:16, 5660.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5826.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:35<00:14, 6280.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:16, 5782.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:34<00:13, 6548.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5803.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:34<00:13, 6525.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:35<00:13, 6494.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  70%|███████   | 219000/311570 [00:34<00:15, 5795.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 5943.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:35<00:13, 6462.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 5897.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:34<00:13, 6482.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 5915.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6588.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:35<00:13, 6436.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6165.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 220000/311570 [00:34<00:15, 5916.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:35<00:13, 6406.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:35<00:14, 6113.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:34<00:13, 6555.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6137.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6370.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6503.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:34<00:14, 6272.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████   | 221000/311570 [00:34<00:14, 6131.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6480.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:35<00:14, 6231.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:35<00:14, 6255.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6328.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6272.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6280.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:34<00:13, 6464.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  71%|███████▏  | 222000/311570 [00:35<00:14, 6239.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:35<00:13, 6412.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6261.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:35<00:13, 6443.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6232.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:35<00:13, 6379.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6192.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:35<00:13, 6405.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 223000/311570 [00:35<00:13, 6425.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:35<00:13, 6351.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6167.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:35<00:13, 6384.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:35<00:13, 6353.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:35<00:12, 6641.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:35<00:13, 6305.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6480.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 224000/311570 [00:35<00:13, 6360.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6425.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:36<00:13, 6281.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6454.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:35<00:12, 6619.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:35<00:12, 6713.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:36<00:12, 6563.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  72%|███████▏  | 225000/311570 [00:35<00:13, 6430.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6263.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:36<00:12, 6533.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:35<00:12, 6686.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6207.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6229.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6696.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:36<00:12, 6643.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 226000/311570 [00:35<00:13, 6219.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6165.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:36<00:12, 6604.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:35<00:12, 6672.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:36<00:13, 6116.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6136.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6300.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6628.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:35<00:13, 6276.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6596.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 227000/311570 [00:35<00:13, 6133.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6283.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:36<00:13, 6230.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:35<00:13, 6254.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6316.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6240.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:35<00:12, 6542.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 228000/311570 [00:36<00:13, 6244.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6214.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:36<00:12, 6488.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:36<00:12, 6522.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6301.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:36<00:12, 6392.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6251.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:36<00:12, 6615.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  73%|███████▎  | 229000/311570 [00:36<00:12, 6501.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:36<00:12, 6557.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6235.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:36<00:12, 6603.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:36<00:12, 6385.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:36<00:12, 6246.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:36<00:12, 6330.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6602.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 230000/311570 [00:36<00:12, 6567.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6536.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:36<00:12, 6303.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6585.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:36<00:12, 6247.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:36<00:11, 6424.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:37<00:12, 6188.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 231000/311570 [00:36<00:12, 6555.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6219.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:37<00:12, 6166.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:36<00:11, 6423.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6165.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6198.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6358.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:37<00:11, 6366.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6231.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  74%|███████▍  | 232000/311570 [00:36<00:12, 6181.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:37<00:11, 6327.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:36<00:11, 6344.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:37<00:12, 6168.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6197.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:11, 6250.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6300.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:36<00:12, 6305.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▍  | 233000/311570 [00:36<00:12, 6197.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6267.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:37<00:12, 6247.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:36<00:11, 6252.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:36<00:12, 6276.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6234.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:11, 6215.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:36<00:12, 6161.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 234000/311570 [00:37<00:12, 6273.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:11, 6178.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6236.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:37<00:12, 6115.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:10, 6546.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:37<00:12, 6135.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6190.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:37<00:11, 6334.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  75%|███████▌  | 235000/311570 [00:37<00:12, 6137.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:10, 6540.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6163.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:37<00:12, 6279.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:37<00:10, 6659.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:37<00:11, 6305.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:11, 6495.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6274.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 236000/311570 [00:37<00:11, 6299.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:37<00:10, 6650.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:11, 6476.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6217.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6245.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:37<00:11, 6276.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:37<00:10, 6608.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:11, 6180.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▌  | 237000/311570 [00:37<00:11, 6237.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:38<00:10, 6584.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:37<00:11, 6272.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:12, 6126.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:11, 6157.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:37<00:10, 6264.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:38<00:11, 6237.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6160.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  76%|███████▋  | 238000/311570 [00:37<00:11, 6145.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:38<00:11, 6210.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:37<00:10, 6250.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6312.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:38<00:11, 6100.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6137.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:38<00:11, 6223.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:11, 6461.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 239000/311570 [00:37<00:11, 6125.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:38<00:11, 6191.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:37<00:10, 6299.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:38<00:11, 6402.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:11, 6439.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6189.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6265.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:37<00:10, 6568.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 240000/311570 [00:37<00:11, 6422.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6238.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:38<00:10, 6514.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:37<00:10, 6548.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6161.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6262.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6124.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  77%|███████▋  | 241000/311570 [00:38<00:10, 6533.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:38<00:11, 6189.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6242.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6109.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:38<00:11, 6143.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:38<00:11, 6177.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:38<00:10, 6377.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6198.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:38<00:11, 6182.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 242000/311570 [00:38<00:11, 6172.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:38<00:10, 6361.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6180.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:38<00:11, 6159.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:38<00:11, 6133.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:38<00:10, 6262.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:38<00:10, 6319.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6233.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 243000/311570 [00:38<00:11, 6147.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:39<00:10, 6293.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:38<00:10, 6249.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:38<00:09, 6402.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6206.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6181.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:39<00:10, 6212.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6102.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  78%|███████▊  | 244000/311570 [00:38<00:10, 6191.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:38<00:09, 6382.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:39<00:10, 6175.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6491.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6070.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:11, 6050.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:39<00:09, 6348.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6178.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:38<00:09, 6474.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▊  | 245000/311570 [00:38<00:10, 6066.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:39<00:09, 6315.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6397.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6137.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:39<00:10, 6117.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6440.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:38<00:10, 6294.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 246000/311570 [00:38<00:10, 6142.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6383.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6410.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6315.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:38<00:10, 6252.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:39<00:10, 6222.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6340.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:38<00:10, 6173.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  79%|███████▉  | 247000/311570 [00:39<00:10, 6259.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6297.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6327.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:39<00:09, 6408.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:39<00:10, 6149.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:39<00:10, 6119.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6258.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:39<00:09, 6311.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:39<00:09, 6395.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 248000/311570 [00:39<00:10, 6150.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:39<00:08, 6594.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6249.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:39<00:09, 6293.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:39<00:10, 6255.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:39<00:09, 6350.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6404.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:39<00:08, 6583.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|███████▉  | 249000/311570 [00:39<00:09, 6278.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:39<00:09, 6346.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:39<00:08, 6478.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6388.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6347.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:40<00:08, 6539.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6324.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:39<00:08, 6473.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  80%|████████  | 250000/311570 [00:39<00:09, 6368.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:40<00:08, 6530.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:39<00:08, 6502.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6301.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6259.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:40<00:08, 6427.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6242.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:39<00:08, 6482.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 251000/311570 [00:39<00:09, 6289.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:40<00:08, 6410.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6546.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6207.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:40<00:08, 6455.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:40<00:09, 6174.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:39<00:09, 6330.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:39<00:08, 6527.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:40<00:08, 6430.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6473.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 252000/311570 [00:39<00:09, 6205.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:39<00:09, 6298.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6510.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:40<00:09, 6267.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:39<00:08, 6498.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6453.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6485.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:40<00:08, 6559.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  81%|████████  | 253000/311570 [00:40<00:09, 6294.87 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:40<00:08, 6479.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:40<00:08, 6446.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6426.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:40<00:08, 6389.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:40<00:08, 6542.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 254000/311570 [00:40<00:08, 6474.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6406.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:40<00:08, 6208.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:40<00:08, 6369.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:40<00:08, 6502.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:40<00:08, 6343.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:40<00:08, 6418.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:40<00:08, 6488.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:40<00:08, 6193.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 255000/311570 [00:40<00:08, 6364.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:40<00:07, 6487.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:40<00:08, 6392.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:40<00:08, 6367.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:41<00:08, 6163.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6475.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:40<00:07, 6478.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 256000/311570 [00:40<00:08, 6388.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:40<00:07, 6433.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:41<00:08, 6144.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6453.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6414.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:41<00:07, 6443.28 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6402.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:40<00:07, 6427.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  82%|████████▏ | 257000/311570 [00:40<00:08, 6442.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:41<00:07, 6412.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6355.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6375.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:41<00:08, 6346.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:41<00:07, 6386.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:40<00:08, 6481.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:40<00:07, 6349.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 258000/311570 [00:40<00:08, 6367.39 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:41<00:07, 6348.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6296.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:40<00:08, 6454.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:41<00:08, 6428.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6310.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:40<00:08, 6136.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6293.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 259000/311570 [00:41<00:08, 6447.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6269.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6224.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:41<00:08, 6113.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6258.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:41<00:08, 6092.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:41<00:07, 6404.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6217.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  83%|████████▎ | 260000/311570 [00:41<00:08, 6112.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6222.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:41<00:07, 6276.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:41<00:07, 6387.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:41<00:07, 6366.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6183.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:41<00:07, 6352.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:41<00:07, 6270.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 261000/311570 [00:41<00:07, 6381.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:41<00:07, 6321.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6153.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:41<00:07, 6332.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:41<00:07, 6304.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:41<00:07, 6234.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6277.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:41<00:07, 6313.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 262000/311570 [00:41<00:07, 6325.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:41<00:06, 6239.31 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:42<00:07, 6206.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6257.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6231.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:42<00:07, 6276.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6219.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:41<00:06, 6231.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6575.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  84%|████████▍ | 263000/311570 [00:41<00:07, 6252.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:42<00:07, 6243.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6202.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6174.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:42<00:07, 6196.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:41<00:06, 6571.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6666.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6143.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▍ | 264000/311570 [00:41<00:07, 6194.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:42<00:07, 6160.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6524.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6123.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:42<00:07, 6097.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:41<00:06, 6671.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:41<00:07, 6195.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6471.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6484.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 265000/311570 [00:41<00:07, 6124.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6624.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:42<00:07, 6169.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:42<00:07, 6145.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6472.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:42<00:06, 6530.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:41<00:07, 6232.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6585.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  85%|████████▌ | 266000/311570 [00:42<00:07, 6170.06 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6420.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:42<00:07, 6207.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:42<00:07, 6182.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:42<00:06, 6526.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:42<00:05, 6446.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:42<00:07, 6144.53 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6391.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 267000/311570 [00:42<00:07, 6213.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:42<00:06, 6476.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:42<00:07, 6128.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:42<00:07, 6101.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:42<00:05, 6440.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6481.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:42<00:05, 6522.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:42<00:06, 6445.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▌ | 268000/311570 [00:42<00:07, 6134.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:43<00:06, 6397.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6453.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6422.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:42<00:05, 6508.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:42<00:05, 6704.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6586.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:43<00:06, 6374.27 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  86%|████████▋ | 269000/311570 [00:42<00:06, 6460.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:43<00:05, 6475.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6554.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6525.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:42<00:05, 6699.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6799.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6396.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:43<00:05, 6444.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 270000/311570 [00:42<00:06, 6557.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:43<00:05, 6653.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6366.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:42<00:05, 6792.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6860.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:43<00:06, 6326.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:42<00:06, 6445.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:43<00:05, 6626.44 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 271000/311570 [00:42<00:06, 6371.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6751.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6866.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:42<00:06, 6410.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:43<00:06, 6380.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6571.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6721.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:42<00:06, 6362.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  87%|████████▋ | 272000/311570 [00:43<00:06, 6421.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6820.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:43<00:06, 6331.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6578.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:43<00:04, 6729.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:43<00:06, 6302.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6791.63 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:43<00:05, 6427.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 273000/311570 [00:43<00:06, 6347.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6523.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:43<00:04, 6736.22 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:43<00:05, 6401.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:43<00:05, 6374.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:43<00:05, 6309.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:43<00:05, 6612.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6501.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:43<00:04, 6673.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 274000/311570 [00:43<00:05, 6411.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:43<00:05, 6583.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:43<00:05, 6554.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:43<00:04, 6318.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6714.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:44<00:04, 6647.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:43<00:04, 6176.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  88%|████████▊ | 275000/311570 [00:43<00:05, 6583.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:44<00:05, 6265.59 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6687.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6646.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6793.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:43<00:04, 6165.08 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 6093.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:44<00:05, 6241.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▊ | 276000/311570 [00:43<00:05, 6678.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6769.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:44<00:04, 6133.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:44<00:05, 6721.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6508.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:43<00:04, 6060.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:44<00:04, 6384.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 277000/311570 [00:43<00:05, 6750.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:44<00:05, 6098.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6478.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 6033.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:44<00:05, 6444.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:43<00:04, 6657.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:43<00:04, 6345.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6568.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  89%|████████▉ | 278000/311570 [00:43<00:05, 6471.88 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 6001.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:43<00:04, 6632.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:44<00:04, 6326.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:44<00:04, 6588.10 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6525.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:44<00:04, 6446.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:43<00:05, 6239.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 279000/311570 [00:44<00:04, 6620.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:44<00:04, 6292.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6502.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:44<00:05, 6224.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:44<00:05, 6185.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:44<00:04, 6398.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:44<00:04, 6321.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:44<00:05, 6096.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6470.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|████████▉ | 280000/311570 [00:44<00:05, 6213.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:44<00:04, 6371.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:44<00:05, 6075.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:44<00:03, 6543.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:44<00:04, 6269.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:44<00:05, 6039.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 6001.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:44<00:04, 6339.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  90%|█████████ | 281000/311570 [00:44<00:05, 6062.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:45<00:04, 6243.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:44<00:03, 6493.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 5974.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:44<00:03, 6273.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 5944.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:44<00:04, 6288.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:45<00:04, 6219.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 282000/311570 [00:44<00:04, 5969.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:45<00:03, 6460.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:44<00:04, 6258.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:44<00:03, 6222.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:45<00:04, 6227.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6469.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6192.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:45<00:03, 6428.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 283000/311570 [00:44<00:04, 6256.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:45<00:03, 6192.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6426.12 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:45<00:04, 6404.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:44<00:03, 6139.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6327.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:44<00:04, 6337.94 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████ | 284000/311570 [00:44<00:04, 6429.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:45<00:03, 6164.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:44<00:04, 6303.64 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6112.99 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:45<00:04, 6282.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6283.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:45<00:03, 6293.78 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:44<00:04, 6211.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  91%|█████████▏| 285000/311570 [00:45<00:04, 6303.46 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6087.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6250.23 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:45<00:04, 6187.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:45<00:02, 6525.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:45<00:03, 6267.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:45<00:04, 6158.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:45<00:03, 6420.79 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6218.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 286000/311570 [00:45<00:04, 6180.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:45<00:03, 6404.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:45<00:03, 6230.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:45<00:03, 6507.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:45<00:03, 6369.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:45<00:03, 6076.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:45<00:03, 6151.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 287000/311570 [00:45<00:03, 6386.95 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:45<00:03, 6206.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:46<00:03, 6464.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:45<00:03, 6140.09 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:45<00:03, 6105.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:45<00:03, 6066.68 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:45<00:02, 6093.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6079.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:46<00:03, 6440.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  92%|█████████▏| 288000/311570 [00:45<00:03, 6118.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:46<00:03, 6038.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6071.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:45<00:02, 6080.18 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6030.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6222.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6151.20 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:46<00:03, 6009.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 289000/311570 [00:45<00:03, 6045.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:46<00:02, 6052.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6203.16 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:46<00:03, 6155.29 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:45<00:02, 6126.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6260.33 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:45<00:03, 6200.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 290000/311570 [00:45<00:03, 6175.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:46<00:02, 6025.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6107.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:45<00:03, 6183.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:46<00:02, 6463.14 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6249.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:45<00:03, 6434.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:46<00:03, 6141.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  93%|█████████▎| 291000/311570 [00:46<00:03, 6153.90 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6077.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:46<00:03, 6413.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6223.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:46<00:02, 6457.03 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:46<00:03, 6372.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:46<00:02, 6293.52 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:46<00:03, 5993.97 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▎| 292000/311570 [00:46<00:03, 6386.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6198.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:46<00:02, 6414.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:46<00:03, 5983.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:46<00:02, 6286.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:46<00:01, 6394.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:46<00:03, 5949.72 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:46<00:02, 6012.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:46<00:02, 6392.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 293000/311570 [00:46<00:03, 5969.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:46<00:02, 6245.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:46<00:01, 6389.82 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:46<00:01, 6449.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:46<00:02, 5998.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:46<00:02, 5969.36 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6067.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:47<00:02, 6220.24 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  94%|█████████▍| 294000/311570 [00:46<00:02, 5986.55 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:47<00:01, 6347.47 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:46<00:01, 6443.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6390.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6048.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6027.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6186.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:47<00:01, 6316.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:47<00:01, 6391.19 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▍| 295000/311570 [00:46<00:02, 6038.85 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:46<00:01, 6367.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6168.35 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6298.05 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:46<00:02, 6381.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:47<00:02, 6126.43 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:47<00:01, 6365.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 296000/311570 [00:46<00:02, 6153.73 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6317.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:46<00:02, 6354.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6274.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:47<00:01, 6164.62 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:47<00:02, 6326.32 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:46<00:02, 6211.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6293.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  95%|█████████▌| 297000/311570 [00:47<00:02, 6346.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6240.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:47<00:02, 6192.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:47<00:01, 6141.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:47<00:01, 6115.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:47<00:01, 6315.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:47<00:02, 6160.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6212.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 298000/311570 [00:47<00:02, 6179.98 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:47<00:01, 6106.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:47<00:01, 6295.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:47<00:01, 6090.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:47<00:01, 6125.38 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:47<00:01, 6360.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:47<00:02, 6258.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:47<00:01, 6080.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▌| 299000/311570 [00:47<00:02, 6279.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:47<00:01, 6054.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:47<00:01, 6351.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:47<00:01, 6092.61 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:47<00:00, 6239.84 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:47<00:01, 6307.65 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6287.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  96%|█████████▋| 300000/311570 [00:47<00:01, 6317.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:48<00:01, 6035.76 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:48<00:01, 6063.86 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6281.66 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:47<00:00, 6205.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6275.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6240.30 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6204.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 301000/311570 [00:47<00:01, 6243.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:48<00:01, 6047.80 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:48<00:00, 6180.54 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6202.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:48<00:00, 6407.17 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:47<00:00, 6238.81 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:48<00:01, 6156.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:47<00:01, 6072.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:48<00:00, 6144.91 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 302000/311570 [00:47<00:01, 6160.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6216.69 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:47<00:00, 6366.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:47<00:01, 6067.41 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:48<00:00, 6289.58 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:48<00:01, 6011.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:47<00:01, 6026.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6179.07 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  97%|█████████▋| 303000/311570 [00:48<00:01, 6025.96 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:48<00:00, 6348.04 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:48<00:00, 6258.51 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:48<00:00, 6316.89 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:48<00:01, 6021.13 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:48<00:01, 5966.67 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:48<00:01, 6035.71 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:48<00:00, 6311.11 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:48<00:00, 6238.25 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 304000/311570 [00:48<00:01, 5985.93 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:48<00:00, 6564.92 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:48<00:00, 6297.60 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:48<00:01, 6026.37 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:48<00:00, 6145.75 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:48<00:01, 5977.59 examples/s]\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:40,060] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:48<00:00, 6201.74 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:48<00:00, 6270.26 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:48<00:00, 6549.48 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 305000/311570 [00:48<00:01, 5992.01 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:48<00:00, 6136.13 examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6180.28 examples/s]\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:40,210] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:48<00:00, 6083.00 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:49<00:00, 6231.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:49<00:00, 6515.56 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  98%|█████████▊| 306000/311570 [00:48<00:00, 6098.83 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6175.74 examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:40,343] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:48<00:00, 6315.50 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6120.77 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:49<00:00, 6479.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▊| 307000/311570 [00:48<00:00, 6131.65 examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:48<00:00, 6307.98 examples/s]\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:40,473] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:48<00:00, 6209.70 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:49<00:00, 6256.40 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 308000/311570 [00:48<00:00, 6267.34 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:48<00:00, 6199.02 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:48<00:00, 6247.57 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:49<00:00, 6142.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 309000/311570 [00:49<00:00, 6174.15 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:49<00:00, 6236.42 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:48<00:00, 6497.21 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:49<00:00, 6187.07 examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:40 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:40,907] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:  99%|█████████▉| 310000/311570 [00:49<00:00, 6211.49 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:49<00:00, 6479.45 examples/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:49<00:00, 6431.33 examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:41 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:41 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:41,026] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|█████████▉| 311000/311570 [00:49<00:00, 6455.79 examples/s]\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:41 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:41 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:41,088] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:41 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ae80bf2ef3f57a6e.arrow\u001b[0m\n",
      "\u001b[34m08/04/2023 16:43:41 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2958d7d1c350e207.arrow and /root/.cache/huggingface/datasets/text/default-b81abc0e6e557f2c/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e930ea813253f431.arrow\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:621] 2023-08-04 16:43:41,146 >> Using cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:621] 2023-08-04 16:43:41,146 >> Using cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:41,150] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.3, git-hash=unknown, git-branch=unknown\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:41,151] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:43:41,160] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mCreating extension directory /root/.cache/torch_extensions/py310_cu118/cpu_adam...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mDetected CUDA files, patching ldflags\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34m[1/3] /opt/conda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o\u001b[0m\n",
      "\u001b[34m[2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o\u001b[0m\n",
      "\u001b[34m[3/3] c++ cpu_adam.o custom_cuda_kernel.cuda.o -shared -lcurand -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/conda/lib64 -lcudart -o cpu_adam.so\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.65428590774536 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.61360025405884 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.60954666137695 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.61120009422302 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.61948108673096 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...Loading extension module cpu_adam...Loading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.741708755493164 seconds\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.74171805381775 seconds\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.741703271865845 seconds\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mCreating extension directory /root/.cache/torch_extensions/py310_cu118/utils...\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/torch_extensions/py310_cu118/utils/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module utils...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34mAdam Optimizer #0 is created with AVX512 arithmetic capability.\u001b[0m\n",
      "\u001b[34mConfig: alpha=0.000006, betas=(0.900000, 0.999000), weight_decay=0.200000, adam_w=1\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,426] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,443] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,443] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,443] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,443] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,615] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,615] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 1.26 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,616] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.15 GB, percent = 7.4%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,617] [INFO] [stage3.py:113:__init__] Reduce bucket size 16777216\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:17,617] [INFO] [stage3.py:114:__init__] Prefetch bucket size 15099494\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34m[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o\u001b[0m\n",
      "\u001b[34m[2/2] c++ flatten_unflatten.o -shared -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.13849139213562 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.01963210105896 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.018802642822266 secondsTime to load utils op: 15.019196033477783 seconds\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.01972770690918 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.019236326217651 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.019041538238525 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 14.918818235397339 seconds\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:32,706] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:32,706] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:32,707] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.11 GB, percent = 7.4%\u001b[0m\n",
      "\u001b[34mParameter Offload: Total persistent parameters: 811008 in 114 params\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:32,866] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:32,867] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:32,867] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.11 GB, percent = 7.4%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:33,009] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:33,009] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:33,010] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.11 GB, percent = 7.4%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:36,431] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 1\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:36,432] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:36,432] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 83.37 GB, percent = 11.1%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:36,592] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:36,593] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:36,593] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 83.37 GB, percent = 11.1%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:37,185] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:37,186] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:37,186] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 86.19 GB, percent = 11.5%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:38,004] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:38,005] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:38,005] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 122.28 GB, percent = 16.4%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:40,850] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:40,851] [INFO] [utils.py:786:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:40,851] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 154.02 GB, percent = 20.6%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:40,852] [INFO] [stage3.py:392:_setup_for_real_optimizer] optimizer state initialized\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...No modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...Loading extension module utils...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.0003628730773925781 secondsTime to load utils op: 0.0003540515899658203 seconds\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.00032806396484375 seconds\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.00040650367736816406 seconds\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.0004050731658935547 seconds\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.0003349781036376953 seconds\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.0004024505615234375 seconds\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,937] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,938] [INFO] [utils.py:786:see_memory_usage] MA 0.14 GB         Max_MA 0.91 GB         CA 1.54 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,938] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 165.49 GB, percent = 22.1%\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,938] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,938] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,939] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f40bbf1cee0>\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[6e-06], mom=[[0.9, 0.999]]\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,939] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   amp_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   amp_params ................... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f40d4019b40>\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   communication_data_type ...... None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   disable_allgather ............ False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,940] [INFO] [config.py:964:print]   dump_state ................... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   elasticity_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   fp16_auto_cast ............... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   fp16_enabled ................. True\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   global_rank .................. 0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 2\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 4096\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   loss_scale ................... 0\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   memory_breakdown ............. False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   mics_shard_size .............. -1\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   optimizer_name ............... adamw\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   optimizer_params ............. {'lr': 6e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.2}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   pld_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   pld_params ................... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   prescale_gradients ........... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   scheduler_name ............... WarmupLR\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 6e-06, 'warmup_num_steps': 43}\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   sparse_attention ............. None\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   steps_per_print .............. 2000\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   train_batch_size ............. 64\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  4\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   use_node_local_storage ....... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,941] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:964:print]   world_size ................... 8\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:964:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:964:print]   zero_enabled ................. True\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:964:print]   zero_optimization_stage ...... 3\u001b[0m\n",
      "\u001b[34m[2023-08-04 16:44:41,942] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 12, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 6e-06, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.2\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 6e-06, \n",
      "            \"warmup_num_steps\": 43\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 1.677722e+07, \n",
      "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 64, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mNo modifications detected for re-loaded extension module utils, skipping build step...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 0.0003666877746582031 seconds\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1769] 2023-08-04 16:44:41,943 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1769] 2023-08-04 16:44:41,943 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1770] 2023-08-04 16:44:41,943 >>   Num examples = 9,077\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1771] 2023-08-04 16:44:41,943 >>   Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1770] 2023-08-04 16:44:41,943 >>   Num examples = 9,077\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1771] 2023-08-04 16:44:41,943 >>   Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1772] 2023-08-04 16:44:41,943 >>   Instantaneous batch size per device = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1773] 2023-08-04 16:44:41,943 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1774] 2023-08-04 16:44:41,943 >>   Gradient Accumulation steps = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1775] 2023-08-04 16:44:41,943 >>   Total optimization steps = 426\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1772] 2023-08-04 16:44:41,943 >>   Instantaneous batch size per device = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1773] 2023-08-04 16:44:41,943 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1774] 2023-08-04 16:44:41,943 >>   Gradient Accumulation steps = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1775] 2023-08-04 16:44:41,943 >>   Total optimization steps = 426\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1776] 2023-08-04 16:44:41,944 >>   Number of trainable parameters = 6,050,882,784\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1776] 2023-08-04 16:44:41,944 >>   Number of trainable parameters = 6,050,882,784\u001b[0m\n",
      "\u001b[34m0%|          | 0/426 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1/426 [00:30<3:38:50, 30.89s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/426 [00:59<3:28:10, 29.46s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 3/426 [01:26<3:21:03, 28.52s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 4/426 [01:52<3:12:34, 27.38s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/426 [02:19<3:12:12, 27.39s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6/426 [02:46<3:09:48, 27.12s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7/426 [03:13<3:09:03, 27.07s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8/426 [03:40<3:08:12, 27.02s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9/426 [04:06<3:05:44, 26.72s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/426 [04:31<3:02:27, 26.31s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3429, 'learning_rate': 3.6731655144641794e-06, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/426 [04:31<3:02:27, 26.31s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 11/426 [04:58<3:03:06, 26.47s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12/426 [05:24<3:01:28, 26.30s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13/426 [05:50<3:00:59, 26.29s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14/426 [06:16<2:59:03, 26.08s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 15/426 [06:43<3:00:30, 26.35s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 16/426 [07:09<2:59:25, 26.26s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 17/426 [07:36<2:59:47, 26.37s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 18/426 [08:03<3:00:50, 26.59s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 19/426 [08:30<3:01:51, 26.81s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 20/426 [08:57<3:00:59, 26.75s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2823, 'learning_rate': 4.7788985133564155e-06, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m5%|▍         | 20/426 [08:57<3:00:59, 26.75s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 16:53:39,022 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 16:53:39,022 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 16:53:39,022 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 16:53:39,023 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 16:53:39,022 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 16:53:39,023 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:30,  1.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:48,  1.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:31<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:48<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:05<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.26953125, 'eval_runtime': 68.0223, 'eval_samples_per_second': 33.371, 'eval_steps_per_second': 0.529, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m5%|▍         | 20/426 [10:05<3:00:59, 26.75s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m5%|▍         | 21/426 [10:31<5:16:54, 46.95s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 22/426 [10:58<4:36:23, 41.05s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 23/426 [11:25<4:07:29, 36.85s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 24/426 [11:53<3:49:00, 34.18s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 25/426 [12:19<3:32:53, 31.85s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 26/426 [12:46<3:22:50, 30.43s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 27/426 [13:13<3:14:20, 29.22s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 28/426 [13:39<3:07:32, 28.27s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 29/426 [14:06<3:04:15, 27.85s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 30/426 [14:33<3:01:46, 27.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.253, 'learning_rate': 5.425710853518323e-06, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m7%|▋         | 30/426 [14:33<3:01:46, 27.54s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 31/426 [14:58<2:57:32, 26.97s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 32/426 [15:24<2:54:46, 26.61s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 33/426 [15:50<2:53:25, 26.48s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 34/426 [16:17<2:53:25, 26.54s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 35/426 [16:43<2:51:55, 26.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 36/426 [17:09<2:51:34, 26.40s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 37/426 [17:37<2:53:00, 26.69s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 38/426 [18:03<2:52:16, 26.64s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 39/426 [18:30<2:52:07, 26.69s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 40/426 [18:56<2:51:16, 26.62s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2443, 'learning_rate': 5.884631512248653e-06, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m9%|▉         | 40/426 [18:56<2:51:16, 26.62s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:03:38,923 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:03:38,923 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:03:38,923 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:03:38,923 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:03:38,923 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:03:38,923 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:52,  1.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.2265625, 'eval_runtime': 68.0026, 'eval_samples_per_second': 33.381, 'eval_steps_per_second': 0.529, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m9%|▉         | 40/426 [20:04<2:51:16, 26.62s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 41/426 [20:30<5:00:12, 46.79s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 42/426 [20:58<4:22:49, 41.07s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 43/426 [21:25<3:55:03, 36.82s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 44/426 [21:52<3:35:46, 33.89s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 45/426 [22:19<3:21:48, 31.78s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 46/426 [22:45<3:11:15, 30.20s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 47/426 [23:12<3:04:50, 29.26s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 48/426 [23:39<2:58:40, 28.36s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 49/426 [24:05<2:54:33, 27.78s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 50/426 [24:31<2:49:56, 27.12s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2318, 'learning_rate': 6e-06, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 50/426 [24:31<2:49:56, 27.12s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 51/426 [24:56<2:46:03, 26.57s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 52/426 [25:22<2:44:19, 26.36s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 53/426 [25:47<2:42:19, 26.11s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 54/426 [26:14<2:43:32, 26.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 55/426 [26:41<2:42:52, 26.34s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 56/426 [27:08<2:44:02, 26.60s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 57/426 [27:34<2:43:08, 26.53s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 58/426 [28:01<2:43:03, 26.59s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 59/426 [28:28<2:44:25, 26.88s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 60/426 [28:55<2:43:44, 26.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2132, 'learning_rate': 6e-06, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 60/426 [28:55<2:43:44, 26.84s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:13:37,707 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:13:37,707 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:13:37,707 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:13:37,707 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:13:37,707 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:13:37,707 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.1953125, 'eval_runtime': 67.9916, 'eval_samples_per_second': 33.386, 'eval_steps_per_second': 0.529, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 60/426 [30:03<2:43:44, 26.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 61/426 [30:31<4:48:54, 47.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 62/426 [30:56<4:07:50, 40.85s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 63/426 [31:23<3:41:07, 36.55s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 64/426 [31:49<3:21:40, 33.43s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 65/426 [32:15<3:08:15, 31.29s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 66/426 [32:42<2:59:14, 29.87s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 67/426 [33:09<2:53:41, 29.03s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 68/426 [33:36<2:50:25, 28.56s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 69/426 [34:03<2:46:35, 28.00s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 70/426 [34:29<2:41:51, 27.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2034, 'learning_rate': 6e-06, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m16%|█▋        | 70/426 [34:29<2:41:51, 27.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 71/426 [34:54<2:38:07, 26.73s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 72/426 [35:20<2:36:01, 26.44s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 73/426 [35:46<2:35:49, 26.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 74/426 [36:13<2:34:50, 26.39s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 75/426 [36:38<2:33:23, 26.22s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 76/426 [37:05<2:32:58, 26.23s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 77/426 [37:31<2:32:56, 26.29s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 78/426 [37:59<2:35:02, 26.73s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 79/426 [38:26<2:34:34, 26.73s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 80/426 [38:54<2:36:18, 27.11s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1736, 'learning_rate': 6e-06, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 80/426 [38:54<2:36:18, 27.11s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:23:36,018 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:23:36,018 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:23:36,018 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:23:36,018 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:23:36,018 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:23:36,018 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.171875, 'eval_runtime': 67.9932, 'eval_samples_per_second': 33.386, 'eval_steps_per_second': 0.529, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 80/426 [40:02<2:36:18, 27.11s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 81/426 [40:29<4:33:13, 47.52s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 82/426 [40:55<3:56:28, 41.25s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 83/426 [41:21<3:29:54, 36.72s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 84/426 [41:48<3:12:05, 33.70s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 85/426 [42:14<2:57:41, 31.27s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 86/426 [42:40<2:48:35, 29.75s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 87/426 [43:06<2:41:04, 28.51s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 88/426 [43:32<2:37:21, 27.93s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 89/426 [43:58<2:33:13, 27.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 90/426 [44:24<2:31:29, 27.05s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1641, 'learning_rate': 6e-06, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34m21%|██        | 90/426 [44:24<2:31:29, 27.05s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 91/426 [44:51<2:30:04, 26.88s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 92/426 [45:18<2:29:56, 26.93s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 93/426 [45:44<2:28:16, 26.72s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 94/426 [46:11<2:28:44, 26.88s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 95/426 [46:39<2:30:08, 27.22s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 96/426 [47:05<2:26:58, 26.72s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 97/426 [47:31<2:26:03, 26.64s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 98/426 [47:58<2:24:49, 26.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 99/426 [48:24<2:25:01, 26.61s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 100/426 [48:52<2:25:51, 26.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1668, 'learning_rate': 6e-06, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 100/426 [48:52<2:25:51, 26.84s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:33:34,311 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 17:33:34,311 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:33:34,312 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:33:34,312 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 17:33:34,312 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 17:33:34,312 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.15234375, 'eval_runtime': 68.0187, 'eval_samples_per_second': 33.373, 'eval_steps_per_second': 0.529, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 100/426 [50:00<2:25:51, 26.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m24%|██▎       | 101/426 [50:27<4:16:06, 47.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 102/426 [50:54<3:42:15, 41.16s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 103/426 [51:21<3:18:27, 36.86s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 104/426 [51:47<3:01:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 105/426 [52:12<2:47:03, 31.22s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 106/426 [52:38<2:37:53, 29.60s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 107/426 [53:05<2:32:15, 28.64s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 108/426 [53:31<2:28:08, 27.95s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 109/426 [53:57<2:24:10, 27.29s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 110/426 [54:23<2:22:06, 26.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1447, 'learning_rate': 6e-06, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 110/426 [54:23<2:22:06, 26.98s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 111/426 [54:50<2:22:14, 27.09s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 112/426 [55:16<2:20:15, 26.80s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 113/426 [55:43<2:18:40, 26.58s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 114/426 [56:10<2:19:35, 26.85s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 115/426 [56:35<2:16:40, 26.37s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 116/426 [57:02<2:16:29, 26.42s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 117/426 [57:27<2:14:10, 26.05s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 182/426 [1:30:33<2:47:11, 41.11s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 183/426 [1:30:59<2:27:39, 36.46s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 184/426 [1:31:27<2:16:12, 33.77s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 185/426 [1:31:52<2:05:42, 31.30s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 186/426 [1:32:19<2:00:00, 30.00s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 187/426 [1:32:45<1:54:51, 28.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 188/426 [1:33:12<1:51:35, 28.13s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 189/426 [1:33:40<1:50:57, 28.09s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 190/426 [1:34:06<1:48:30, 27.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9481, 'learning_rate': 6e-06, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m45%|████▍     | 190/426 [1:34:06<1:48:30, 27.59s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 191/426 [1:34:32<1:46:28, 27.19s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 192/426 [1:34:59<1:45:10, 26.97s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 193/426 [1:35:26<1:44:28, 26.90s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 194/426 [1:35:52<1:43:44, 26.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 195/426 [1:36:18<1:42:13, 26.55s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 196/426 [1:36:46<1:42:43, 26.80s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 197/426 [1:37:13<1:43:19, 27.07s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 198/426 [1:37:39<1:41:40, 26.76s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 199/426 [1:38:06<1:40:49, 26.65s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 200/426 [1:38:31<1:38:29, 26.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9443, 'learning_rate': 6e-06, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 200/426 [1:38:31<1:38:29, 26.15s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:23:13,119 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:23:13,119 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:23:13,119 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:23:13,119 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:23:13,119 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:23:13,119 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:52,  1.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.080078125, 'eval_runtime': 68.0137, 'eval_samples_per_second': 33.376, 'eval_steps_per_second': 0.529, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 200/426 [1:39:39<1:38:29, 26.15s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 201/426 [1:40:05<2:55:06, 46.70s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 202/426 [1:40:32<2:32:27, 40.84s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 203/426 [1:40:59<2:15:52, 36.56s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 204/426 [1:41:24<2:02:19, 33.06s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 205/426 [1:41:50<1:53:57, 30.94s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 206/426 [1:42:18<1:49:47, 29.94s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 207/426 [1:42:44<1:45:09, 28.81s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 208/426 [1:43:11<1:43:35, 28.51s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 209/426 [1:43:38<1:40:54, 27.90s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 210/426 [1:44:04<1:38:06, 27.25s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9426, 'learning_rate': 6e-06, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 210/426 [1:44:04<1:38:06, 27.25s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 211/426 [1:44:31<1:37:30, 27.21s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 212/426 [1:44:57<1:36:23, 27.03s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 213/426 [1:45:24<1:35:39, 26.95s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 214/426 [1:45:51<1:35:31, 27.04s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 215/426 [1:46:17<1:33:25, 26.57s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 216/426 [1:46:43<1:32:52, 26.54s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 217/426 [1:47:10<1:32:44, 26.62s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 218/426 [1:47:37<1:32:57, 26.81s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 219/426 [1:48:04<1:32:25, 26.79s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 220/426 [1:48:31<1:31:52, 26.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9482, 'learning_rate': 6e-06, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 220/426 [1:48:31<1:31:52, 26.76s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:33:13,375 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:33:13,375 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:33:13,376 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:33:13,376 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:33:13,376 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:33:13,376 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:44,  1.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:52,  1.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.064453125, 'eval_runtime': 68.0067, 'eval_samples_per_second': 33.379, 'eval_steps_per_second': 0.529, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 220/426 [1:49:39<1:31:52, 26.76s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 221/426 [1:50:06<2:41:29, 47.27s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 222/426 [1:50:32<2:19:25, 41.01s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 223/426 [1:50:59<2:04:36, 36.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 224/426 [1:51:26<1:53:09, 33.61s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 225/426 [1:51:52<1:45:35, 31.52s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 226/426 [1:52:18<1:39:34, 29.87s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 227/426 [1:52:44<1:34:49, 28.59s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 228/426 [1:53:10<1:31:58, 27.87s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 229/426 [1:53:35<1:28:50, 27.06s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 230/426 [1:54:02<1:27:59, 26.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9164, 'learning_rate': 6e-06, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 230/426 [1:54:02<1:27:59, 26.93s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 231/426 [1:54:28<1:27:05, 26.80s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 232/426 [1:54:55<1:26:13, 26.67s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 233/426 [1:55:20<1:24:13, 26.19s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 234/426 [1:55:46<1:23:58, 26.24s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 235/426 [1:56:12<1:23:21, 26.18s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 236/426 [1:56:39<1:23:20, 26.32s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 237/426 [1:57:04<1:22:16, 26.12s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 238/426 [1:57:30<1:21:46, 26.10s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 239/426 [1:57:58<1:22:24, 26.44s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 240/426 [1:58:25<1:22:20, 26.56s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9118, 'learning_rate': 6e-06, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 240/426 [1:58:25<1:22:20, 26.56s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:43:07,076 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:43:07,076 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:43:07,076 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:43:07,076 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:43:07,076 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:43:07,076 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:32,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:44,  1.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:52,  1.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.05078125, 'eval_runtime': 67.997, 'eval_samples_per_second': 33.384, 'eval_steps_per_second': 0.529, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 240/426 [1:59:33<1:22:20, 26.56s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 241/426 [1:59:59<2:24:45, 46.95s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 242/426 [2:00:24<2:03:31, 40.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 243/426 [2:00:51<1:50:29, 36.23s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 244/426 [2:01:16<1:39:59, 32.97s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 245/426 [2:01:41<1:32:01, 30.50s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 246/426 [2:02:07<1:27:42, 29.24s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 247/426 [2:02:34<1:25:22, 28.62s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 248/426 [2:03:00<1:22:46, 27.90s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 249/426 [2:03:27<1:21:16, 27.55s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 250/426 [2:03:55<1:20:43, 27.52s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.918, 'learning_rate': 6e-06, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 250/426 [2:03:55<1:20:43, 27.52s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 251/426 [2:04:20<1:18:50, 27.03s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 252/426 [2:04:48<1:18:50, 27.19s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 253/426 [2:05:15<1:17:52, 27.01s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 254/426 [2:05:42<1:17:29, 27.03s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 255/426 [2:06:07<1:15:48, 26.60s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 256/426 [2:06:34<1:15:11, 26.54s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 257/426 [2:06:59<1:13:34, 26.12s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 258/426 [2:07:26<1:13:46, 26.35s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 259/426 [2:07:53<1:14:00, 26.59s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 260/426 [2:08:20<1:13:39, 26.62s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.905, 'learning_rate': 6e-06, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m61%|██████    | 260/426 [2:08:20<1:13:39, 26.62s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:53:02,060 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 18:53:02,060 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:53:02,060 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 18:53:02,060 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:53:02,060 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 18:53:02,060 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:45,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:34,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:34<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:51<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.0390625, 'eval_runtime': 68.0855, 'eval_samples_per_second': 33.34, 'eval_steps_per_second': 0.529, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m61%|██████    | 260/426 [2:09:28<1:13:39, 26.62s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 261/426 [2:09:53<2:08:01, 46.55s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 262/426 [2:10:20<1:51:11, 40.68s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 263/426 [2:10:45<1:38:26, 36.23s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 264/426 [2:11:12<1:29:53, 33.29s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 265/426 [2:11:38<1:23:26, 31.10s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 266/426 [2:12:04<1:18:56, 29.60s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 267/426 [2:12:30<1:15:57, 28.66s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 268/426 [2:12:57<1:13:40, 27.98s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 269/426 [2:13:23<1:12:03, 27.54s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 270/426 [2:13:50<1:10:33, 27.14s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9014, 'learning_rate': 6e-06, 'epoch': 1.9}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 270/426 [2:13:50<1:10:33, 27.14s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 271/426 [2:14:16<1:09:51, 27.04s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 272/426 [2:14:43<1:08:48, 26.81s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 273/426 [2:15:08<1:07:30, 26.47s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 274/426 [2:15:35<1:07:04, 26.47s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 275/426 [2:16:00<1:05:44, 26.12s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 276/426 [2:16:27<1:05:39, 26.26s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 277/426 [2:16:54<1:05:51, 26.52s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 278/426 [2:17:20<1:05:27, 26.54s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 279/426 [2:17:47<1:04:43, 26.42s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 280/426 [2:18:12<1:03:33, 26.12s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9218, 'learning_rate': 6e-06, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 280/426 [2:18:12<1:03:33, 26.12s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:02:54,441 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:02:54,441 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:02:54,441 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:02:54,441 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:02:54,441 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:02:54,441 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:34,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.02734375, 'eval_runtime': 67.9632, 'eval_samples_per_second': 33.4, 'eval_steps_per_second': 0.53, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 280/426 [2:19:20<1:03:33, 26.12s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 281/426 [2:19:47<1:52:48, 46.68s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 282/426 [2:20:13<1:37:46, 40.74s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 283/426 [2:20:40<1:26:43, 36.39s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 284/426 [2:21:06<1:18:54, 33.34s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 285/426 [2:21:32<1:12:57, 31.05s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 286/426 [2:21:58<1:09:26, 29.76s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 287/426 [2:22:24<1:06:20, 28.63s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 288/426 [2:22:52<1:04:56, 28.24s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 289/426 [2:23:17<1:02:41, 27.45s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 290/426 [2:23:44<1:01:26, 27.10s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7738, 'learning_rate': 6e-06, 'epoch': 2.04}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 290/426 [2:23:44<1:01:26, 27.10s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 291/426 [2:24:10<1:00:23, 26.84s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 292/426 [2:24:36<59:15, 26.54s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 293/426 [2:25:02<58:38, 26.45s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 294/426 [2:25:29<58:31, 26.60s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 295/426 [2:25:55<57:29, 26.33s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 296/426 [2:26:21<56:59, 26.31s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 297/426 [2:26:47<56:12, 26.14s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 298/426 [2:27:12<55:27, 25.99s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 299/426 [2:27:39<55:21, 26.16s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 300/426 [2:28:05<55:00, 26.19s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7071, 'learning_rate': 6e-06, 'epoch': 2.11}\u001b[0m\n",
      "\u001b[34m70%|███████   | 300/426 [2:28:05<55:00, 26.19s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:12:47,517 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:12:47,517 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:12:47,517 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:12:47,517 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:12:47,517 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:12:47,517 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:51<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.056640625, 'eval_runtime': 68.1212, 'eval_samples_per_second': 33.323, 'eval_steps_per_second': 0.528, 'epoch': 2.11}\u001b[0m\n",
      "\u001b[34m70%|███████   | 300/426 [2:29:13<55:00, 26.19s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 36/36 [01:06<00:00,  1.89s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 301/426 [2:29:40<1:37:45, 46.93s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 302/426 [2:30:07<1:24:38, 40.96s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 303/426 [2:30:31<1:13:14, 35.73s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 304/426 [2:30:57<1:06:53, 32.90s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 305/426 [2:31:24<1:02:57, 31.22s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 306/426 [2:31:49<58:38, 29.32s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 307/426 [2:32:15<56:10, 28.32s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 308/426 [2:32:42<54:48, 27.87s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 309/426 [2:33:07<52:37, 26.99s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 310/426 [2:33:33<51:47, 26.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6773, 'learning_rate': 6e-06, 'epoch': 2.18}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 310/426 [2:33:33<51:47, 26.79s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 311/426 [2:34:00<51:18, 26.77s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 312/426 [2:34:28<51:18, 27.01s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 313/426 [2:34:55<50:54, 27.03s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 314/426 [2:35:20<49:16, 26.40s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 315/426 [2:35:46<48:31, 26.23s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 316/426 [2:36:12<48:18, 26.35s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 317/426 [2:36:38<47:24, 26.10s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 318/426 [2:37:04<47:11, 26.21s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 319/426 [2:37:30<46:35, 26.12s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 320/426 [2:37:56<45:46, 25.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.692, 'learning_rate': 6e-06, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 320/426 [2:37:56<45:46, 25.91s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:22:38,030 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:22:38,030 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:22:38,030 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:22:38,030 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:22:38,030 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:22:38,030 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:34,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:51<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.04296875, 'eval_runtime': 68.1227, 'eval_samples_per_second': 33.322, 'eval_steps_per_second': 0.528, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 320/426 [2:39:04<45:46, 25.91s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 321/426 [2:39:30<1:21:31, 46.59s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 322/426 [2:39:56<1:09:49, 40.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 323/426 [2:40:22<1:01:44, 35.96s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 324/426 [2:40:49<56:26, 33.20s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 325/426 [2:41:15<52:15, 31.04s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 326/426 [2:41:40<48:41, 29.21s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 327/426 [2:42:07<47:17, 28.66s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 328/426 [2:42:33<45:25, 27.81s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 329/426 [2:43:00<44:34, 27.57s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 330/426 [2:43:25<43:01, 26.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6858, 'learning_rate': 6e-06, 'epoch': 2.32}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 330/426 [2:43:25<43:01, 26.89s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 331/426 [2:43:51<42:10, 26.63s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 332/426 [2:44:17<41:36, 26.56s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 333/426 [2:44:43<40:49, 26.34s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 334/426 [2:45:09<40:00, 26.10s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 335/426 [2:45:36<40:08, 26.47s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 336/426 [2:46:01<38:59, 26.00s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 337/426 [2:46:28<38:54, 26.23s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 338/426 [2:46:55<38:54, 26.53s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 339/426 [2:47:19<37:25, 25.81s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 340/426 [2:47:45<37:11, 25.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6995, 'learning_rate': 6e-06, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 340/426 [2:47:45<37:11, 25.95s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:32:27,947 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:32:27,947 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:32:27,948 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:32:27,948 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:32:27,948 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:32:27,948 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:42,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:31<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:17,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.037109375, 'eval_runtime': 68.0182, 'eval_samples_per_second': 33.373, 'eval_steps_per_second': 0.529, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 340/426 [2:48:54<37:11, 25.95s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 341/426 [2:49:21<1:06:17, 46.79s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 342/426 [2:49:47<56:45, 40.54s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 343/426 [2:50:14<50:28, 36.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 344/426 [2:50:41<46:03, 33.70s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 345/426 [2:51:06<42:08, 31.22s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 346/426 [2:51:31<39:06, 29.33s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 347/426 [2:51:57<37:18, 28.34s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 348/426 [2:52:24<36:03, 27.74s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 349/426 [2:52:50<35:06, 27.35s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 350/426 [2:53:16<33:58, 26.82s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6627, 'learning_rate': 6e-06, 'epoch': 2.46}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 350/426 [2:53:16<33:58, 26.82s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 351/426 [2:53:41<32:57, 26.36s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 352/426 [2:54:06<32:07, 26.05s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 353/426 [2:54:33<31:44, 26.10s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 354/426 [2:54:58<31:08, 25.96s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 355/426 [2:55:24<30:41, 25.93s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 356/426 [2:55:51<30:43, 26.33s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 357/426 [2:56:18<30:22, 26.41s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 358/426 [2:56:44<29:54, 26.39s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 359/426 [2:57:10<29:13, 26.17s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 360/426 [2:57:36<28:42, 26.10s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6813, 'learning_rate': 6e-06, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 360/426 [2:57:36<28:42, 26.10s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:42:18,439 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:42:18,439 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:42:18,439 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:42:18,439 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:42:18,439 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:42:18,439 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:42,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:31<00:33,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:31,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:48<00:16,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:05<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.03125, 'eval_runtime': 67.8577, 'eval_samples_per_second': 33.452, 'eval_steps_per_second': 0.531, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 360/426 [2:58:44<28:42, 26.10s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 361/426 [2:59:12<50:57, 47.04s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 362/426 [2:59:37<43:14, 40.55s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 363/426 [3:00:05<38:24, 36.58s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 364/426 [3:00:31<34:45, 33.64s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 365/426 [3:00:58<32:12, 31.68s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 366/426 [3:01:25<30:03, 30.05s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 367/426 [3:01:51<28:26, 28.92s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 368/426 [3:02:17<27:07, 28.07s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 369/426 [3:02:43<26:10, 27.55s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 370/426 [3:03:10<25:19, 27.13s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6753, 'learning_rate': 6e-06, 'epoch': 2.61}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 370/426 [3:03:10<25:19, 27.13s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 371/426 [3:03:37<24:57, 27.24s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 372/426 [3:04:03<24:04, 26.74s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 373/426 [3:04:29<23:32, 26.65s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 374/426 [3:04:55<22:55, 26.46s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 375/426 [3:05:22<22:43, 26.73s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 376/426 [3:05:47<21:46, 26.12s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 377/426 [3:06:13<21:18, 26.08s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 378/426 [3:06:40<21:02, 26.31s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 379/426 [3:07:06<20:32, 26.22s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 380/426 [3:07:32<20:02, 26.14s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6712, 'learning_rate': 6e-06, 'epoch': 2.68}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 380/426 [3:07:32<20:02, 26.14s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:52:14,438 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 19:52:14,438 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:52:14,438 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:52:14,438 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 19:52:14,438 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 19:52:14,438 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:44,  1.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:52,  1.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:17<00:48,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:33,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.021484375, 'eval_runtime': 68.0349, 'eval_samples_per_second': 33.365, 'eval_steps_per_second': 0.529, 'epoch': 2.68}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 380/426 [3:08:40<20:02, 26.14s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 403/426 [3:19:51<13:54, 36.29s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 404/426 [3:20:18<12:17, 33.53s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 405/426 [3:20:44<10:57, 31.29s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 406/426 [3:21:11<09:58, 29.92s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 407/426 [3:21:37<09:03, 28.58s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 408/426 [3:22:02<08:17, 27.62s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 409/426 [3:22:28<07:42, 27.24s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 410/426 [3:22:56<07:15, 27.24s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6746, 'learning_rate': 6e-06, 'epoch': 2.89}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 410/426 [3:22:56<07:15, 27.24s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 411/426 [3:23:22<06:45, 27.05s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 412/426 [3:23:48<06:12, 26.57s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 413/426 [3:24:14<05:43, 26.42s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 414/426 [3:24:40<05:16, 26.36s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 415/426 [3:25:06<04:49, 26.36s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 416/426 [3:25:32<04:23, 26.31s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 417/426 [3:25:58<03:55, 26.21s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 418/426 [3:26:23<03:26, 25.82s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 419/426 [3:26:50<03:01, 26.00s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 420/426 [3:27:16<02:36, 26.13s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.643, 'learning_rate': 6e-06, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 420/426 [3:27:16<02:36, 26.13s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 20:11:58,636 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3129] 2023-08-04 20:11:58,636 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 20:11:58,636 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 20:11:58,636 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3131] 2023-08-04 20:11:58,636 >>   Num examples = 2270\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3134] 2023-08-04 20:11:58,636 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/36 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 2/36 [00:01<00:31,  1.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/36 [00:03<00:43,  1.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 4/36 [00:05<00:49,  1.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 5/36 [00:07<00:51,  1.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 6/36 [00:09<00:51,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/36 [00:11<00:51,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/36 [00:13<00:50,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 9/36 [00:15<00:49,  1.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 10/36 [00:16<00:48,  1.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 11/36 [00:18<00:46,  1.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 12/36 [00:20<00:44,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 13/36 [00:22<00:43,  1.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 14/36 [00:24<00:41,  1.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 15/36 [00:26<00:39,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 16/36 [00:28<00:37,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 17/36 [00:30<00:35,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 18/36 [00:32<00:34,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 19/36 [00:33<00:32,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 20/36 [00:35<00:30,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 21/36 [00:37<00:28,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 22/36 [00:39<00:26,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 23/36 [00:41<00:24,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 24/36 [00:43<00:22,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 25/36 [00:45<00:20,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 26/36 [00:47<00:18,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 27/36 [00:49<00:16,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 28/36 [00:50<00:15,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 29/36 [00:52<00:13,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 30/36 [00:54<00:11,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 31/36 [00:56<00:09,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 32/36 [00:58<00:07,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 33/36 [01:00<00:05,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 34/36 [01:02<00:03,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 35/36 [01:04<00:01,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.998046875, 'eval_runtime': 68.0204, 'eval_samples_per_second': 33.372, 'eval_steps_per_second': 0.529, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 420/426 [3:28:24<02:36, 26.13s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 36/36 [01:06<00:00,  1.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 421/426 [3:28:50<03:52, 46.54s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 422/426 [3:29:17<02:42, 40.67s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"'loss': ([0-9]+\\.[0-9]+)\"},\n",
    "    {\"Name\": \"eval:loss\", \"Regex\": \"'eval_loss': ([0-9]+\\.[0-9]+)\"},\n",
    "    {\"Name\": \"eval:runtime\", \"Regex\": \"'eval_runtime': ([0-9]+\\.[0-9]+)\"},\n",
    "    {\"Name\": \"eval:samples_per_second\", \"Regex\": \"'eval_samples_per_second': ([0-9]+\\.[0-9]+)\"},\n",
    "    {\"Name\": \"eval:eval_steps_per_second\", \"Regex\": \"'eval_steps_per_second': ([0-9]+\\.[0-9]+)\"},\n",
    "]\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tg_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    "    metric_definitions=metric_definitions,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    ")\n",
    "\n",
    "if use_amt:\n",
    "    hp_tuner = HyperparameterTuner(\n",
    "        tg_estimator,\n",
    "        amt_metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "        hyperparameter_ranges,\n",
    "        amt_metric_definitions[\"metrics\"],\n",
    "        max_jobs=max_jobs,\n",
    "        max_parallel_jobs=max_parallel_jobs,\n",
    "        objective_type=amt_metric_definitions[\"type\"],\n",
    "        base_tuning_job_name=training_job_name,\n",
    "        instruction_tuned=False\n",
    "    )\n",
    "\n",
    "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "    hp_tuner.fit({\"train\": training_dataset_s3_path })\n",
    "else:\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    tg_estimator.fit(\n",
    "        {\"train\": training_dataset_s3_path}, logs=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd7886-1895-4b93-932b-a41d9c97fdc8",
   "metadata": {},
   "source": [
    "## Review Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be261a3-68ef-4f9f-9683-363ad2e3677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import TrainingJobAnalytics\n",
    "\n",
    "if use_amt:\n",
    "    training_job_name = hp_tuner.best_training_job()\n",
    "else:\n",
    "    training_job_name = tg_estimator.latest_training_job.job_name\n",
    "\n",
    "df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ac4f7-0250-406e-a55a-13ba4c71bb8c",
   "metadata": {},
   "source": [
    "## Deploy & run Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7453f-681c-45c1-b171-f5739e775662",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.g5.12xlarge\"\n",
    "\n",
    "# Retrieve the docker container uri for inference\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "endpoint_name_after_finetune = name_from_base(f\"ssides-hugging-face-{model_id}-\")\n",
    "\n",
    "# Deploy to SageMaker endpoint\n",
    "finetuned_predictor = (hp_tuner if use_amt else tg_estimator).deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    image_uri=deploy_image_uri,\n",
    "    endpoint_name=endpoint_name_after_finetune,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc72ef4-217d-4f43-a7e0-61db33794f0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference Helper functions\n",
    "Creates two helper functions that will be used when we call the inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6c064-11c3-41aa-a5d7-8522ace181dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "def query_endpoint_with_payload(encoded_json, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    generated_text = []\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    return model_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fba258-0977-4a4f-804f-146124eb8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_length\": 500,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.8,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 1,\n",
    "}\n",
    "\n",
    "res_gpt_finetune = []\n",
    "    \n",
    "for quota_text in [\n",
    "    \"Tell me about the Matrimonial and Family Proceedings Act 1984\",\n",
    "]:\n",
    "    payload = {\"text_inputs\": f\"{quota_text}:\", **parameters}\n",
    "\n",
    "    query_response = query_endpoint_with_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name_after_finetune\n",
    "    )\n",
    "    generated_texts = parse_response_multiple_texts(query_response)[0][\"generated_text\"]\n",
    "    res_gpt_finetune.append(generated_texts)\n",
    "    print(generated_texts)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec6142-d74f-4a40-8463-244e86c8c87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65c836-3009-4477-bea1-41254bc2eddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
